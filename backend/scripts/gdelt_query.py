"""
GDELT æ–°é—»æŸ¥è¯¢è„šæœ¬
==================

ä½¿ç”¨ GDELT 2.0 Doc API æŸ¥è¯¢å†å²æ–°é—»

æ³¨æ„ï¼šGDELT 2.0 Doc API å®˜æ–¹åªæ”¯æŒæœ€è¿‘ 3 ä¸ªæœˆçš„æ–°é—»
å¦‚éœ€æŸ¥è¯¢æ›´ä¹…çš„å†å²æ•°æ®ï¼Œéœ€è¦ä½¿ç”¨ Google BigQuery

ä½¿ç”¨æ–¹æ³•:
    python gdelt_query.py "èŒ…å°" --days 90
    python gdelt_query.py "è´µå·èŒ…å°" --start 2024-10-01 --end 2024-12-31
"""

import argparse
from datetime import datetime, timedelta
from typing import Optional
import pandas as pd

try:
    from gdeltdoc import GdeltDoc, Filters

    GDELT_AVAILABLE = True
except ImportError:
    GDELT_AVAILABLE = False
    print("âš ï¸ gdeltdoc æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install gdeltdoc")


class GDELTNewsClient:
    """GDELT æ–°é—»æŸ¥è¯¢å®¢æˆ·ç«¯"""

    # GDELT API é™åˆ¶ï¼šæœ€å¤š 3 ä¸ªæœˆ
    MAX_DAYS = 90

    # ä¸­æ–‡è‚¡ç¥¨åç§°åˆ°è‹±æ–‡çš„æ˜ å°„
    STOCK_NAME_MAP = {
        "èŒ…å°": "Kweichow Moutai",
        "è´µå·èŒ…å°": "Kweichow Moutai",
        "æ¯”äºšè¿ª": "BYD",
        "å®å¾·æ—¶ä»£": "CATL",
        "ä¸­çŸ³æ²¹": "PetroChina",
        "ä¸­çŸ³åŒ–": "Sinopec",
        "å·¥å•†é“¶è¡Œ": "ICBC",
        "å»ºè®¾é“¶è¡Œ": "CCB",
        "æ‹›å•†é“¶è¡Œ": "CMB China Merchants Bank",
        "å¹³å®‰": "Ping An",
        "è…¾è®¯": "Tencent",
        "é˜¿é‡Œå·´å·´": "Alibaba",
        "äº¬ä¸œ": "JD.com",
        "å°ç±³": "Xiaomi",
        "åä¸º": "Huawei",
        "å­—èŠ‚è·³åŠ¨": "ByteDance",
        "ç¾å›¢": "Meituan",
        "ç™¾åº¦": "Baidu",
        "ç½‘æ˜“": "NetEase",
    }

    def __init__(self):
        if not GDELT_AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£… gdeltdoc: pip install gdeltdoc")
        self.client = GdeltDoc()

    def _translate_keyword(self, keyword: str) -> str:
        """å°†ä¸­æ–‡å…³é”®è¯è½¬æ¢ä¸ºè‹±æ–‡ï¼ˆGDELT å¯¹ä¸­æ–‡æ”¯æŒè¾ƒå·®ï¼‰"""
        # å…ˆæ£€æŸ¥æ˜ å°„è¡¨
        if keyword in self.STOCK_NAME_MAP:
            translated = self.STOCK_NAME_MAP[keyword]
            print(f"ğŸ“ å…³é”®è¯è½¬æ¢: '{keyword}' â†’ '{translated}'")
            return translated

        # å¦‚æœå…³é”®è¯å¤ªçŸ­ï¼ˆå°‘äº4ä¸ªå­—ç¬¦ï¼‰ï¼Œå°è¯•æ‰©å±•
        if len(keyword) < 4:
            # å¯¹äºä¸­æ–‡ï¼Œæ¯ä¸ªå­—ç¬¦ç®—1ä¸ªï¼ŒGDELTè¦æ±‚è‡³å°‘4ä¸ªå­—ç¬¦
            expanded = f"{keyword} China stock"
            print(f"ğŸ“ å…³é”®è¯æ‰©å±•: '{keyword}' â†’ '{expanded}'")
            return expanded

        return keyword

    def search(
        self,
        keyword: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        days: int = 30,
        country: Optional[list] = None,
        domain: Optional[list] = None,
        language: str = "Chinese",
    ) -> pd.DataFrame:
        """
        æœç´¢ GDELT æ–°é—»

        Args:
            keyword: æœç´¢å…³é”®è¯
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸º end_date - days
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
            days: æŸ¥è¯¢å¤©æ•°ï¼ˆå¦‚æœæœªæŒ‡å®š start_dateï¼‰ï¼Œæœ€å¤§ 90 å¤©
            country: å›½å®¶è¿‡æ»¤ï¼Œå¦‚ ["China"]
            domain: åŸŸåè¿‡æ»¤ï¼Œå¦‚ ["sina.com.cn", "eastmoney.com"]
            language: è¯­è¨€è¿‡æ»¤

        Returns:
            æ–°é—» DataFrame
        """
        # å¤„ç†æ—¥æœŸ
        if end_date is None:
            end_dt = datetime.now()
        else:
            end_dt = datetime.strptime(end_date, "%Y-%m-%d")

        if start_date is None:
            # é™åˆ¶æœ€å¤§å¤©æ•°
            actual_days = min(days, self.MAX_DAYS)
            if days > self.MAX_DAYS:
                print(f"âš ï¸ GDELT API é™åˆ¶ï¼šæœ€å¤šæŸ¥è¯¢ {self.MAX_DAYS} å¤©ï¼Œå·²è‡ªåŠ¨è°ƒæ•´")
            start_dt = end_dt - timedelta(days=actual_days)
        else:
            start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            # æ£€æŸ¥æ—¥æœŸèŒƒå›´
            date_diff = (end_dt - start_dt).days
            if date_diff > self.MAX_DAYS:
                print(f"âš ï¸ GDELT API é™åˆ¶ï¼šæœ€å¤šæŸ¥è¯¢ {self.MAX_DAYS} å¤©")
                print(f"   è¯·æ±‚èŒƒå›´ {date_diff} å¤©ï¼Œå°†åˆ†æ‰¹æŸ¥è¯¢...")
                return self._batch_search(
                    keyword, start_dt, end_dt, country, domain, language
                )

        return self._single_search(
            keyword,
            start_dt.strftime("%Y-%m-%d"),
            end_dt.strftime("%Y-%m-%d"),
            country,
            domain,
            language,
        )

    def _single_search(
        self,
        keyword: str,
        start_date: str,
        end_date: str,
        country: Optional[list] = None,
        domain: Optional[list] = None,
        language: str = "Chinese",
    ) -> pd.DataFrame:
        """æ‰§è¡Œå•æ¬¡æŸ¥è¯¢"""
        # è½¬æ¢å…³é”®è¯ï¼ˆå¤„ç†ä¸­æ–‡ï¼‰
        search_keyword = self._translate_keyword(keyword)
        print(f"ğŸ” æŸ¥è¯¢: '{search_keyword}' ({start_date} ~ {end_date})")

        try:
            # æ„å»ºè¿‡æ»¤å™¨
            filter_args = {
                "keyword": search_keyword,
                "start_date": start_date,
                "end_date": end_date,
            }

            if country:
                filter_args["country"] = country
            if domain:
                filter_args["domain"] = domain

            filters = Filters(**filter_args)

            # æ‰§è¡ŒæŸ¥è¯¢
            articles = self.client.article_search(filters)

            if articles is not None and not articles.empty:
                print(f"âœ… æ‰¾åˆ° {len(articles)} æ¡æ–°é—»")
                return articles
            else:
                print("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ–°é—»")
                return pd.DataFrame()

        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            return pd.DataFrame()

    def _batch_search(
        self,
        keyword: str,
        start_dt: datetime,
        end_dt: datetime,
        country: Optional[list] = None,
        domain: Optional[list] = None,
        language: str = "Chinese",
    ) -> pd.DataFrame:
        """åˆ†æ‰¹æŸ¥è¯¢ï¼ˆå¤„ç†è¶…è¿‡ 90 å¤©çš„è¯·æ±‚ï¼‰"""
        all_results = []
        current_end = end_dt

        while current_end > start_dt:
            current_start = max(start_dt, current_end - timedelta(days=self.MAX_DAYS))

            df = self._single_search(
                keyword,
                current_start.strftime("%Y-%m-%d"),
                current_end.strftime("%Y-%m-%d"),
                country,
                domain,
                language,
            )

            if not df.empty:
                all_results.append(df)

            current_end = current_start - timedelta(days=1)

        if all_results:
            combined = pd.concat(all_results, ignore_index=True)
            # å»é‡
            if "url" in combined.columns:
                combined = combined.drop_duplicates(subset=["url"])
            print(f"ğŸ“Š åˆè®¡æ‰¾åˆ° {len(combined)} æ¡æ–°é—»")
            return combined

        return pd.DataFrame()

    def search_stock_news(self, stock_name: str, days: int = 30) -> pd.DataFrame:
        """
        æŸ¥è¯¢è‚¡ç¥¨ç›¸å…³æ–°é—»ï¼ˆé’ˆå¯¹ä¸­å›½è‚¡ç¥¨ä¼˜åŒ–ï¼‰

        Args:
            stock_name: è‚¡ç¥¨åç§°ï¼Œå¦‚ "èŒ…å°"ã€"æ¯”äºšè¿ª"
            days: æŸ¥è¯¢å¤©æ•°

        Returns:
            æ–°é—» DataFrame
        """
        # ä¸­å›½è´¢ç»æ–°é—»åŸŸå
        cn_finance_domains = [
            "sina.com.cn",
            "eastmoney.com",
            "10jqka.com.cn",
            "163.com",
            "qq.com",
            "hexun.com",
            "caixin.com",
            "yicai.com",
        ]

        return self.search(
            keyword=stock_name, days=days, country=["China"], domain=cn_finance_domains
        )


def format_news_output(df: pd.DataFrame, limit: int = 20) -> str:
    """æ ¼å¼åŒ–æ–°é—»è¾“å‡º"""
    if df.empty:
        return "æœªæ‰¾åˆ°ç›¸å…³æ–°é—»"

    output = []
    output.append(f"\n{'=' * 80}")
    output.append(f"å…±æ‰¾åˆ° {len(df)} æ¡æ–°é—» (æ˜¾ç¤ºå‰ {min(limit, len(df))} æ¡)")
    output.append(f"{'=' * 80}\n")

    # è·å–åˆ—å
    title_col = next((c for c in ["title", "Title"] if c in df.columns), None)
    url_col = next((c for c in ["url", "URL"] if c in df.columns), None)
    date_col = next(
        (c for c in ["seendate", "DateTime", "date"] if c in df.columns), None
    )
    domain_col = next((c for c in ["domain", "Domain"] if c in df.columns), None)

    for i, (_, row) in enumerate(df.head(limit).iterrows(), 1):
        title = row[title_col] if title_col else "N/A"
        url = row[url_col] if url_col else ""
        date = row[date_col] if date_col else ""
        domain = row[domain_col] if domain_col else ""

        # æˆªæ–­è¿‡é•¿çš„æ ‡é¢˜
        if len(str(title)) > 80:
            title = title[:77] + "..."

        output.append(f"{i:2d}. [{date[:10] if date else 'N/A'}] {title}")
        if domain:
            output.append(f"    æ¥æº: {domain}")
        if url:
            output.append(f"    é“¾æ¥: {url[:80]}...")
        output.append("")

    return "\n".join(output)


def main():
    parser = argparse.ArgumentParser(
        description="GDELT æ–°é—»æŸ¥è¯¢å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python gdelt_query.py "èŒ…å°"
  python gdelt_query.py "èŒ…å°" --days 90
  python gdelt_query.py "è´µå·èŒ…å°" --start 2024-10-01 --end 2024-12-31
  python gdelt_query.py "æ¯”äºšè¿ª" --stock  # ä½¿ç”¨ä¸­å›½è´¢ç»ç½‘ç«™è¿‡æ»¤
  python gdelt_query.py "èŒ…å°" --output news.csv  # ä¿å­˜åˆ°æ–‡ä»¶

æ³¨æ„: GDELT 2.0 Doc API å®˜æ–¹åªæ”¯æŒæœ€è¿‘ 3 ä¸ªæœˆçš„æ–°é—»
      å¦‚éœ€æŸ¥è¯¢ä¸€å¹´æˆ–æ›´ä¹…çš„å†å²ï¼Œè¯·ä½¿ç”¨ Google BigQuery
        """,
    )

    parser.add_argument("keyword", help="æœç´¢å…³é”®è¯")
    parser.add_argument(
        "--days", type=int, default=30, help="æŸ¥è¯¢å¤©æ•° (é»˜è®¤: 30, æœ€å¤§: 90)"
    )
    parser.add_argument("--start", help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--end", help="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument(
        "--stock", action="store_true", help="è‚¡ç¥¨æ–°é—»æ¨¡å¼ï¼ˆä½¿ç”¨ä¸­å›½è´¢ç»ç½‘ç«™è¿‡æ»¤ï¼‰"
    )
    parser.add_argument("--output", "-o", help="è¾“å‡ºåˆ° CSV æ–‡ä»¶")
    parser.add_argument("--limit", type=int, default=20, help="æ˜¾ç¤ºæ¡æ•° (é»˜è®¤: 20)")

    args = parser.parse_args()

    if not GDELT_AVAILABLE:
        print("âŒ è¯·å…ˆå®‰è£… gdeltdoc: pip install gdeltdoc")
        return

    client = GDELTNewsClient()

    # æ‰§è¡ŒæŸ¥è¯¢
    if args.stock:
        df = client.search_stock_news(args.keyword, days=args.days)
    else:
        df = client.search(
            keyword=args.keyword,
            start_date=args.start,
            end_date=args.end,
            days=args.days,
        )

    # è¾“å‡ºç»“æœ
    print(format_news_output(df, limit=args.limit))

    # ä¿å­˜åˆ°æ–‡ä»¶
    if args.output and not df.empty:
        df.to_csv(args.output, index=False, encoding="utf-8-sig")
        print(f"âœ… å·²ä¿å­˜åˆ° {args.output}")

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not df.empty and "domain" in df.columns:
        print("\nğŸ“Š æ¥æºåˆ†å¸ƒ:")
        domain_counts = df["domain"].value_counts().head(10)
        for domain, count in domain_counts.items():
            print(f"   {domain}: {count} æ¡")


if __name__ == "__main__":
    main()
