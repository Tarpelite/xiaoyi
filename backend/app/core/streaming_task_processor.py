"""
æµå¼ä»»åŠ¡å¤„ç†å™¨
===============

å®Œå…¨æµå¼æ¶æ„ - æ‰€æœ‰æ­¥éª¤çš„è¾“å‡ºéƒ½é€šè¿‡ SSE å®æ—¶è¿”å›
æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼šæµå¼æ•°æ®åŒæ—¶å­˜å…¥ Redis
"""

import asyncio
import os  # ç”¨äºè¯»å–ç¯å¢ƒå˜é‡
import json
import traceback
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any, Callable, Awaitable

from app.core.session import Session, Message
from app.core.redis_client import get_redis
from app.schemas.session_schema import (
    TimeSeriesPoint,
    UnifiedIntent,
    ResolvedKeywords,
    StockMatchResult,
    SummarizedNewsItem,
)

# Services
from app.services.stock_matcher import get_stock_matcher
from app.services.rag_client import check_rag_availability

# Agents
from app.agents import (
    IntentAgent,
    ReportAgent,
    ErrorExplainerAgent,
    SentimentAgent,
    NewsSummaryAgent,
)

# Data clients
from app.data.rag_searcher import RAGSearcher

# Data & Models
from app.data.fetcher import DataFetchError
from app.models import TimeSeriesAnalyzer

# Workflows
from app.core.workflows import (
    fetch_stock_data,
    fetch_news_all,
    fetch_rag_reports,
    search_web,
    fetch_domain_news,
    run_forecast,
    df_to_points,
    recommend_forecast_params,
    select_best_model,
)


class StreamingTaskProcessor:
    """
    æµå¼ä»»åŠ¡å¤„ç†å™¨

    æ ¸å¿ƒæµç¨‹ï¼ˆå…¨ç¨‹æµå¼ï¼‰:
    1. æ„å›¾è¯†åˆ« - æµå¼è¿”å›æ€è€ƒè¿‡ç¨‹
    2. è‚¡ç¥¨éªŒè¯ - è¿”å›åŒ¹é…ç»“æœ
    3. æ•°æ®è·å– - è¿”å›å†å²æ•°æ®å’Œæ–°é—»
    4. åˆ†æå¤„ç† - è¿”å›ç‰¹å¾å’Œæƒ…ç»ª
    5. æ¨¡å‹é¢„æµ‹ - è¿”å›é¢„æµ‹ç»“æœ
    6. æŠ¥å‘Šç”Ÿæˆ - æµå¼è¿”å›æŠ¥å‘Šå†…å®¹
    """

    # Baseline æƒ©ç½šæœºåˆ¶å¼€å…³
    # True: å¯ç”¨æƒ©ç½šæœºåˆ¶ï¼Œç”¨æˆ·æŒ‡å®šæ¨¡å‹ä¸å¦‚ baseline æ—¶é™çº§ä¸º baseline
    # False: ç¦ç”¨æƒ©ç½šæœºåˆ¶ï¼Œå³ä½¿æœ€ä½³æ¨¡å‹ä¸å¦‚ baseline ä¹Ÿä½¿ç”¨æœ€ä½³æ¨¡å‹
    ENABLE_BASELINE_PENALTY = False

    def __init__(self):
        self.intent_agent = IntentAgent()
        self.rag_searcher = RAGSearcher()
        self.report_agent = ReportAgent()
        self.error_explainer = ErrorExplainerAgent()
        self.sentiment_agent = SentimentAgent()
        self.news_summary_agent = NewsSummaryAgent()
        self.stock_matcher = get_stock_matcher()
        self.redis = get_redis()

    async def execute_streaming(
        self,
        session_id: str,
        message_id: str,
        user_input: str,
        event_queue: asyncio.Queue | None,
        model_name: Optional[str] = None,
    ):
        """
        æ‰§è¡Œå®Œå…¨æµå¼ä»»åŠ¡

        Args:
            session_id: ä¼šè¯ ID
            message_id: æ¶ˆæ¯ ID
            user_input: ç”¨æˆ·è¾“å…¥
            event_queue: äº‹ä»¶é˜Ÿåˆ—ï¼ˆå‘é€åˆ° SSEï¼Œåå°ä»»åŠ¡æ—¶ä¸º Noneï¼‰
            model_name: é¢„æµ‹æ¨¡å‹åç§°
        """
        session = Session(session_id)
        message = Message(message_id, session_id)

        # è®¾ç½®æµå¼çŠ¶æ€
        self._update_stream_status(message, "streaming")

        try:
            conversation_history = session.get_conversation_history()

            # === Step 1: æ„å›¾è¯†åˆ«ï¼ˆæµå¼ï¼‰ ===
            await self._emit_event(
                event_queue,
                message,
                {"type": "step_start", "step": 1, "step_name": "æ„å›¾è¯†åˆ«"},
            )

            message.update_step_detail(1, "running", "åˆ†æç”¨æˆ·æ„å›¾...")

            intent, thinking_content = await self._step_intent_streaming(
                user_input, conversation_history, event_queue, message
            )

            if not intent:
                await self._emit_error(event_queue, message, "æ„å›¾è¯†åˆ«å¤±è´¥")
                return

            # å¦‚æœç”¨æˆ·é€šè¿‡ API æŒ‡å®šäº†æ¨¡å‹ï¼Œè¦†ç›–æ„å›¾è¯†åˆ«çš„ç»“æœ
            print(f"[ModelSelection] API ä¼ å…¥çš„ model_name: {model_name}")
            print(
                f"[ModelSelection] æ„å›¾è¯†åˆ«è¿”å›çš„ forecast_model: {intent.forecast_model}"
            )
            if model_name is not None:
                intent.forecast_model = model_name
                print(f"[ModelSelection] ä½¿ç”¨ API æŒ‡å®šçš„æ¨¡å‹: {model_name}")
            else:
                # å¦‚æœç”¨æˆ·æ²¡æœ‰é€šè¿‡ API æŒ‡å®šæ¨¡å‹ï¼Œä¸” LLM è¿”å›çš„æ˜¯ "prophet"ï¼ˆå¯èƒ½æ˜¯é»˜è®¤å€¼ï¼‰ï¼Œ
                # åˆ™å°†å…¶è®¾ä¸º Noneï¼Œè§¦å‘è‡ªåŠ¨æ¨¡å‹é€‰æ‹©
                if intent.forecast_model == "prophet":
                    print(
                        f"[ModelSelection] æ£€æµ‹åˆ° LLM è¿”å›äº† 'prophet'ï¼Œå°†å…¶è®¾ä¸º None ä»¥è§¦å‘è‡ªåŠ¨é€‰æ‹©"
                    )
                    intent.forecast_model = None
                else:
                    print(
                        f"[ModelSelection] LLM è¿”å›çš„æ¨¡å‹ä¸æ˜¯ 'prophet'ï¼Œä¿æŒåŸå€¼: {intent.forecast_model}"
                    )

            # ä¿å­˜æ„å›¾
            message.save_unified_intent(intent)
            message.append_thinking_log("intent", "æ„å›¾è¯†åˆ«", thinking_content)

            # å‘é€æ„å›¾ç»“æœ
            await self._emit_event(
                event_queue,
                message,
                {
                    "type": "intent",
                    "intent": "forecast" if intent.is_forecast else "chat",
                    "is_forecast": intent.is_forecast,
                    "reason": intent.reason,
                },
            )

            # å¤„ç†è¶…å‡ºèŒƒå›´
            if not intent.is_in_scope:
                reply = (
                    intent.out_of_scope_reply
                    or "æŠ±æ­‰ï¼Œæˆ‘æ˜¯é‡‘èæ—¶åºåˆ†æåŠ©æ‰‹ï¼Œæš‚ä¸æ”¯æŒæ­¤ç±»é—®é¢˜ã€‚"
                )
                message.save_conclusion(reply)
                message.update_step_detail(1, "completed", "è¶…å‡ºæœåŠ¡èŒƒå›´")
                message.mark_completed()
                self._update_stream_status(message, "completed")
                await self._emit_event(
                    event_queue,
                    message,
                    {"type": "chat_chunk", "content": reply, "is_complete": True},
                )
                await self._emit_done(event_queue, message)
                return

            await self._emit_event(
                event_queue,
                message,
                {
                    "type": "step_complete",
                    "step": 1,
                    "data": {"intent": "forecast" if intent.is_forecast else "chat"},
                },
            )
            message.update_step_detail(
                1, "completed", f"æ„å›¾: {'é¢„æµ‹' if intent.is_forecast else 'å¯¹è¯'}"
            )

            # === Step 2: è‚¡ç¥¨éªŒè¯ ===
            stock_match_result = None
            resolved_keywords = None

            if intent.stock_mention:
                await self._emit_event(
                    event_queue,
                    message,
                    {"type": "step_start", "step": 2, "step_name": "è‚¡ç¥¨éªŒè¯"},
                )

                query_name = intent.stock_full_name or intent.stock_mention
                message.update_step_detail(2, "running", f"éªŒè¯è‚¡ç¥¨: {query_name}")

                stock_match_result = await asyncio.to_thread(
                    self.stock_matcher.match, query_name
                )

                message.save_stock_match(stock_match_result)

                if not stock_match_result.success:
                    error_msg = stock_match_result.error_message or "è‚¡ç¥¨éªŒè¯å¤±è´¥"
                    message.save_conclusion(error_msg)
                    message.update_step_detail(2, "error", error_msg)
                    message.mark_completed()
                    self._update_stream_status(message, "error")
                    await self._emit_error(event_queue, message, error_msg)
                    return

                stock_info = stock_match_result.stock_info
                resolved_keywords = self.intent_agent.resolve_keywords(
                    intent,
                    stock_name=stock_info.stock_name if stock_info else None,
                    stock_code=stock_info.stock_code if stock_info else None,
                )
                message.save_resolved_keywords(resolved_keywords)

                await self._emit_event(
                    event_queue,
                    message,
                    {
                        "type": "step_complete",
                        "step": 2,
                        "data": {
                            "stock_code": stock_info.stock_code if stock_info else "",
                            "stock_name": stock_info.stock_name if stock_info else "",
                        },
                    },
                )
                message.update_step_detail(
                    2,
                    "completed",
                    f"åŒ¹é…: {stock_info.stock_name}({stock_info.stock_code})"
                    if stock_info
                    else "æ— åŒ¹é…",
                )
            else:
                resolved_keywords = ResolvedKeywords(
                    search_keywords=intent.raw_search_keywords,
                    rag_keywords=intent.raw_rag_keywords,
                    domain_keywords=intent.raw_domain_keywords,
                )

            # === æ ¹æ®æ„å›¾æ‰§è¡Œä¸åŒæµç¨‹ ===
            if intent.is_forecast:
                await self._execute_forecast_streaming(
                    message,
                    session,
                    user_input,
                    intent,
                    stock_match_result,
                    resolved_keywords,
                    conversation_history,
                    event_queue,
                )
            else:
                await self._execute_chat_streaming(
                    message,
                    session,
                    user_input,
                    intent,
                    stock_match_result,
                    resolved_keywords,
                    conversation_history,
                    event_queue,
                )

            # æ ‡è®°å®Œæˆ
            message.mark_completed()
            self._update_stream_status(message, "completed")

            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
            data = message.get()
            if data and data.conclusion:
                session.add_conversation_message("assistant", data.conclusion)

            await self._emit_done(event_queue, message)

        except Exception as e:
            print(f"âŒ Streaming task error: {traceback.format_exc()}")
            message.mark_error(str(e))
            self._update_stream_status(message, "error")
            await self._emit_error(event_queue, message, str(e))

    # ========== æµå¼æ„å›¾è¯†åˆ« ==========

    async def _step_intent_streaming(
        self,
        user_input: str,
        conversation_history: List[dict],
        event_queue: asyncio.Queue | None,
        message: Message,
    ) -> tuple:
        """æµå¼æ„å›¾è¯†åˆ«"""
        import queue as thread_queue

        chunk_queue: thread_queue.Queue = thread_queue.Queue()

        def on_chunk(chunk: str):
            """åŒæ­¥å›è°ƒ - æ”¾å…¥çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—"""
            chunk_queue.put(chunk)

        def run_intent():
            """åœ¨çº¿ç¨‹ä¸­è¿è¡Œæ„å›¾è¯†åˆ«"""
            result = self.intent_agent.recognize_intent_streaming(
                user_input, conversation_history, on_chunk
            )
            chunk_queue.put(None)  # ç»“æŸæ ‡è®°
            return result

        # å¯åŠ¨çº¿ç¨‹ä»»åŠ¡
        loop = asyncio.get_running_loop()
        future = loop.run_in_executor(None, run_intent)

        # è½®è¯¢é˜Ÿåˆ—ï¼Œé€šè¿‡ _emit_event å‘é€äº‹ä»¶
        thinking_content = ""
        while True:
            try:
                chunk = chunk_queue.get_nowait()
                if chunk is None:
                    break
                thinking_content += chunk
                await self._emit_event(
                    event_queue,
                    message,
                    {"type": "thinking", "content": thinking_content},
                )
            except thread_queue.Empty:
                if future.done():
                    # å¤„ç†å‰©ä½™çš„ chunks
                    while not chunk_queue.empty():
                        chunk = chunk_queue.get_nowait()
                        if chunk is not None:
                            thinking_content += chunk
                            await self._emit_event(
                                event_queue,
                                message,
                                {"type": "thinking", "content": thinking_content},
                            )
                    break
                await asyncio.sleep(0.01)

        intent, final_thinking = await future
        return intent, final_thinking or thinking_content

    # ========== é¢„æµ‹æµç¨‹ï¼ˆæµå¼ï¼‰ ==========

    async def _execute_forecast_streaming(
        self,
        message: Message,
        session: Session,
        user_input: str,
        intent: UnifiedIntent,
        stock_match: Optional[StockMatchResult],
        keywords: ResolvedKeywords,
        conversation_history: List[dict],
        event_queue: asyncio.Queue | None,
    ):
        """æµå¼é¢„æµ‹æµç¨‹"""
        stock_info = stock_match.stock_info if stock_match else None
        stock_code = stock_info.stock_code if stock_info else ""
        stock_name = stock_info.stock_name if stock_info else user_input

        # === Step 3: æ•°æ®è·å– ===
        await self._emit_event(
            event_queue,
            message,
            {"type": "step_start", "step": 3, "step_name": "æ•°æ®è·å–"},
        )
        message.update_step_detail(3, "running", "è·å–å†å²æ•°æ®å’Œæ–°é—»...")

        end_date = datetime.now().strftime("%Y%m%d")
        start_date = (datetime.now() - timedelta(days=intent.history_days)).strftime(
            "%Y%m%d"
        )

        # å¹¶è¡Œè·å–æ•°æ®
        stock_data_task = asyncio.create_task(
            fetch_stock_data(stock_code, start_date, end_date)
        )
        news_task = asyncio.create_task(
            fetch_news_all(stock_code, stock_name, intent.history_days)
        )
        rag_available = await check_rag_availability() if intent.enable_rag else False
        rag_task = (
            asyncio.create_task(
                fetch_rag_reports(self.rag_searcher, keywords.rag_keywords)
            )
            if intent.enable_rag and rag_available
            else None
        )

        # ä¼˜å…ˆè·å–è‚¡ç¥¨æ•°æ®
        try:
            stock_result = await stock_data_task
        except Exception as e:
            stock_result = e

        # å¤„ç†è‚¡ç¥¨æ•°æ®
        df = None
        if isinstance(stock_result, DataFetchError):
            error_explanation = await asyncio.to_thread(
                self.error_explainer.explain_data_fetch_error, stock_result, user_input
            )
            message.save_conclusion(error_explanation)
            message.update_step_detail(3, "error", "æ•°æ®è·å–å¤±è´¥")
            news_task.cancel()
            if rag_task:
                rag_task.cancel()
            await self._emit_error(event_queue, message, error_explanation)
            return
        elif isinstance(stock_result, Exception):
            error_msg = f"è·å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(stock_result)}"
            message.save_conclusion(error_msg)
            message.update_step_detail(3, "error", "æ•°æ®è·å–å¤±è´¥")
            news_task.cancel()
            if rag_task:
                rag_task.cancel()
            await self._emit_error(event_queue, message, error_msg)
            return
        else:
            df = stock_result

        if df is None or df.empty:
            error_msg = f"æ— æ³•è·å– {stock_name} çš„å†å²æ•°æ®ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ã€‚"
            message.save_conclusion(error_msg)
            message.update_step_detail(3, "error", "æ•°æ®è·å–å¤±è´¥")
            news_task.cancel()
            if rag_task:
                rag_task.cancel()
            await self._emit_error(event_queue, message, error_msg)
            return

        # ç«‹å³ä¿å­˜å¹¶å‘é€è‚¡ç¥¨æ•°æ®
        original_points = df_to_points(df, is_prediction=False)
        message.save_time_series_original(original_points)

        await self._emit_event(
            event_queue,
            message,
            {
                "type": "data",
                "data_type": "time_series_original",
                "data": [p.model_dump() for p in original_points],
            },
        )

        # ç­‰å¾…æ–°é—»å’Œ RAG
        pending_tasks = [news_task]
        if rag_task:
            pending_tasks.append(rag_task)

        other_results = await asyncio.gather(*pending_tasks, return_exceptions=True)

        news_result = (
            other_results[0]
            if not isinstance(other_results[0], Exception)
            else ([], {})
        )
        rag_sources = (
            other_results[1]
            if len(other_results) > 1
            and not isinstance(other_results[1], Exception)
            and intent.enable_rag
            else []
        )

        news_items, sentiment_result = news_result

        # æ€»ç»“æ–°é—» - ç›´æ¥è°ƒç”¨ Agent
        if news_items:
            summarized_news, _ = await asyncio.to_thread(
                self.news_summary_agent.summarize, news_items
            )
        else:
            summarized_news = []

        message.save_news(summarized_news)

        # å‘é€æ–°é—»æ•°æ®
        if summarized_news:
            await self._emit_event(
                event_queue,
                message,
                {
                    "type": "data",
                    "data_type": "news",
                    "data": [n.model_dump() for n in summarized_news],
                },
            )

        if rag_sources:
            message.save_rag_sources(rag_sources)

        # === è®¡ç®—å¼‚å¸¸åŒºåŸŸï¼ˆåœ¨Step 3å®Œæˆå‰ï¼Œç¡®ä¿resumeæ—¶èƒ½è·å–åˆ°ï¼‰===
        print(
            f"[AnomalyZones] Starting dynamic clustering for message {message.message_id}"
        )
        try:
            import pandas as pd
            from app.services.stock_signal_service import StockSignalService
            from app.agents.event_summary_agent import EventSummaryAgent

            # ä» df æå–æ—¥æœŸã€æ”¶ç›˜ä»·ã€æˆäº¤é‡
            sig_df = pd.DataFrame(
                {
                    "date": df["ds"].dt.strftime("%Y-%m-%d"),
                    "close": df["y"],
                    "volume": df.get("volume", [1] * len(df)),
                }
            )

            # æ„å»ºæ–°é—»è®¡æ•°å­—å…¸ï¼ˆæŒ‰æ—¥æœŸï¼‰
            news_counts = {}
            for news_item in summarized_news or []:
                try:
                    date_key = (
                        news_item.published_date[:10]
                        if news_item.published_date
                        else None
                    )
                    if date_key:
                        news_counts[date_key] = news_counts.get(date_key, 0) + 1
                except Exception as e:
                    pass

            # === Redis å…¨å±€ç¼“å­˜æ£€æŸ¥ ===
            redis_client = get_redis()
            cache_key = f"stock_zones:{stock_code}"
            cached_zones_json = None

            try:
                cached_zones_json = redis_client.get(cache_key)
                if cached_zones_json:
                    import json

                    anomaly_zones = json.loads(cached_zones_json)
                    print(
                        f"[AnomalyZones] âœ“ Using Redis cached {len(anomaly_zones)} zones for {stock_code}"
                    )
            except Exception as e:
                print(f"[AnomalyZones] Redis cache read error: {e}")
                cached_zones_json = None

            # å¦‚æœç¼“å­˜ä¸å­˜åœ¨ï¼Œè®¡ç®—å¹¶ä¿å­˜
            if not cached_zones_json:
                # ä½¿ç”¨åŠ¨æ€èšç±»æœåŠ¡ (Merged into StockSignalService)
                clustering_service = StockSignalService(lookback=60, max_zone_days=10)
                anomaly_zones = clustering_service.generate_zones(sig_df, news_counts)

                print(
                    f"[AnomalyZones] âš™ï¸ Generated {len(anomaly_zones)} zones: {[z['zone_type'] for z in anomaly_zones]}"
                )

            # ä¸ºæ¯ä¸ªåŒºåŸŸç”Ÿæˆäº‹ä»¶æ‘˜è¦ï¼ˆä»…å½“ä¸æ˜¯ä»ç¼“å­˜è¯»å–æ—¶ï¼‰
            if anomaly_zones and not cached_zones_json:
                try:
                    event_agent = EventSummaryAgent()

                    # å¯¼å…¥MongoDB clientï¼ˆä»stock_db.pyï¼‰
                    from app.data.stock_db import get_mongo_client

                    mongo_client = None

                    try:
                        mongo_client = get_mongo_client()
                        # ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®æ•°æ®åº“å’Œé›†åˆåç§°
                        db_name = os.getenv("MONGODB_DATABASE", "EastMoneyGubaNews")
                        collection_name = os.getenv("MONGODB_COLLECTION", "stock_news")
                        news_collection = mongo_client[db_name][collection_name]

                        for zone in anomaly_zones:
                            start = zone["startDate"]
                            end = zone["endDate"]

                            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥è¯¢åŒºåŸŸå†…çš„æ–°é—»
                            zone_dates = []
                            current = datetime.strptime(start, "%Y-%m-%d")
                            end_dt = datetime.strptime(end, "%Y-%m-%d")
                            while current <= end_dt:
                                zone_dates.append(current.strftime("%Y-%m-%d"))
                                current += timedelta(days=1)

                            # ä»MongoDBæŸ¥è¯¢è¿™äº›æ—¥æœŸçš„æ‰€æœ‰å†…å®¹ï¼ˆèµ„è®¯ã€ç ”æŠ¥ã€å…¬å‘Šï¼‰
                            regex_pattern = "^(" + "|".join(zone_dates) + ")"
                            zone_news_cursor = news_collection.find(
                                {
                                    "stock_code": stock_code,
                                    "publish_time": {"$regex": regex_pattern},
                                    # ä¸è¿‡æ»¤content_typeï¼ŒåŒ…å«æ‰€æœ‰ç±»å‹
                                }
                            ).limit(20)  # å¢åŠ åˆ°20æ¡ä»¥è¦†ç›–æ›´å¤šå†…å®¹ç±»å‹

                            zone_news_dicts = []
                            for news_doc in zone_news_cursor:
                                zone_news_dicts.append(
                                    {
                                        "title": news_doc.get("title", ""),
                                        "content_type": news_doc.get(
                                            "content_type", "èµ„è®¯"
                                        ),
                                        "publish_time": news_doc.get(
                                            "publish_time", ""
                                        ),
                                    }
                                )

                            # ä½¿ç”¨Agentç”Ÿæˆæ‘˜è¦
                            event_summary = event_agent.summarize_zone(
                                zone_dates=zone_dates,
                                price_change=zone["avg_return"] * 100,
                                news_items=zone_news_dicts,
                            )

                            zone["event_summary"] = event_summary
                            print(
                                f"[AnomalyZones] Zone {start}-{end} ({len(zone_news_dicts)} news): {event_summary}"
                            )

                    finally:
                        if mongo_client:
                            mongo_client.close()

                except Exception as e:
                    import traceback

                    print(f"[AnomalyZones] Error generating event summaries: {e}")
                    print(f"[AnomalyZones] Traceback: {traceback.format_exc()}")
                    # Fallback: ä½¿ç”¨ç®€å•æ‘˜è¦
                    for zone in anomaly_zones:
                        if "event_summary" not in zone:
                            zone["event_summary"] = (
                                f"ä»·æ ¼å˜åŒ–{zone.get('avg_return', 0) * 100:+.1f}%"
                            )

            # è¿‡æ»¤æ‰æ²¡æœ‰æ–°é—»çš„zonesï¼ˆä»…å½“ä¸æ˜¯ä»ç¼“å­˜è¯»å–æ—¶ï¼‰
            if not cached_zones_json:
                anomaly_zones_with_news = []
                for zone in anomaly_zones:
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°é—»ï¼ˆé€šè¿‡event_summaryåˆ¤æ–­ï¼ŒåŒ…å«"è‚¡ä»·"è¯´æ˜æ²¡æœ‰æ–°é—»ï¼‰
                    if (
                        zone.get("event_summary")
                        and not zone["event_summary"].startswith("è‚¡ä»·")
                        and not zone["event_summary"].startswith("ä»·æ ¼")
                    ):
                        anomaly_zones_with_news.append(zone)
                    else:
                        print(
                            f"[AnomalyZones] Filtered out zone {zone['startDate']}-{zone['endDate']} (no news)"
                        )

                anomaly_zones = anomaly_zones_with_news
                print(
                    f"[AnomalyZones] After filtering: {len(anomaly_zones)} zones with news"
                )

                # === ä¿å­˜åˆ°Rediså…¨å±€ç¼“å­˜ ===
                if anomaly_zones:
                    try:
                        import json

                        zones_json = json.dumps(anomaly_zones, ensure_ascii=False)
                        redis_client.setex(
                            cache_key,
                            12 * 60 * 60,  # 12å°æ—¶TTL
                            zones_json,
                        )
                        print(
                            f"[AnomalyZones] ğŸ’¾ Saved {len(anomaly_zones)} zones to Redis cache (12 hours)"
                        )
                    except Exception as e:
                        print(f"[AnomalyZones] Redis cache save error: {e}")

            # ä¿å­˜å¹¶å‘é€å¼‚å¸¸åŒºåŸŸæ•°æ®
            if anomaly_zones:
                message.save_anomaly_zones(anomaly_zones, stock_code)

                await self._emit_event(
                    event_queue,
                    message,
                    {
                        "type": "data",
                        "data_type": "anomaly_zones",
                        "data": {"zones": anomaly_zones, "ticker": stock_code},
                    },
                )
                print(f"[AnomalyZones] Successfully saved and emitted")

        except Exception as e:
            import traceback

            print(f"[AnomalyZones] Error: {e}")
            print(f"[AnomalyZones] Traceback:\n{traceback.format_exc()}")

        await self._emit_event(
            event_queue,
            message,
            {
                "type": "step_complete",
                "step": 3,
                "data": {"data_points": len(df), "news_count": len(news_items)},
            },
        )
        message.update_step_detail(
            3, "completed", f"å†å²æ•°æ® {len(df)} å¤©, æ–°é—» {len(news_items)} æ¡"
        )

        # === Step 4: åˆ†æå¤„ç†ï¼ˆæƒ…ç»ªæµå¼è¾“å‡ºï¼‰===
        await self._emit_event(
            event_queue,
            message,
            {"type": "step_start", "step": 4, "step_name": "åˆ†æå¤„ç†"},
        )
        message.update_step_detail(4, "running", "åˆ†ææ—¶åºç‰¹å¾å’Œå¸‚åœºæƒ…ç»ª...")

        # æ—¶åºç‰¹å¾åˆ†æ
        features = await asyncio.to_thread(TimeSeriesAnalyzer.analyze_features, df)

        # æµå¼æƒ…ç»ªåˆ†æ
        emotion_result = await self._step_sentiment_streaming(
            summarized_news, event_queue, message
        )

        message.save_emotion(
            emotion_result.get("score", 0), emotion_result.get("description", "ä¸­æ€§")
        )

        await self._emit_event(
            event_queue,
            message,
            {
                "type": "step_complete",
                "step": 4,
                "data": {
                    "trend": features.get("trend", "N/A"),
                    "emotion": emotion_result.get("description", "ä¸­æ€§"),
                },
            },
        )
        message.update_step_detail(
            4,
            "completed",
            f"è¶‹åŠ¿: {features.get('trend', 'N/A')}, æƒ…ç»ª: {emotion_result.get('description', 'N/A')}",
        )

        # === Step 5: æ¨¡å‹é¢„æµ‹ ===
        await self._emit_event(
            event_queue,
            message,
            {"type": "step_start", "step": 5, "step_name": "æ¨¡å‹é¢„æµ‹"},
        )
        message.update_step_detail(5, "running", f"è®­ç»ƒæ¨¡å‹...")

        prophet_params = await recommend_forecast_params(
            self.sentiment_agent, emotion_result or {}, features
        )

        # è®¡ç®—é¢„æµ‹å¤©æ•°
        last_date = df["ds"].max().to_pydatetime()
        target_date_from_start = last_date + timedelta(days=90)
        print(f"[ModelSelection] ç›®æ ‡æ—¥æœŸä»å¼€å§‹: {target_date_from_start}")
        target_date_to_today = datetime.now()
        print(f"[ModelSelection] ç›®æ ‡æ—¥æœŸåˆ°ä»Šå¤©: {target_date_to_today}")
        target_date = max(target_date_from_start, target_date_to_today)
        print(f"[ModelSelection] ç›®æ ‡æ—¥æœŸ: {target_date}")
        forecast_horizon = max((target_date - last_date).days, 1)
        print(f"[ModelSelection] é¢„æµ‹å¤©æ•°: {forecast_horizon}")

        # æ¨¡å‹é€‰æ‹©ï¼šæ„å»ºå€™é€‰æ¨¡å‹åˆ—è¡¨
        candidate_models = ["prophet", "xgboost", "randomforest", "dlinear"]
        user_specified_model = intent.forecast_model
        print(f"[ModelSelection] ç”¨æˆ·æŒ‡å®šæ¨¡å‹: {user_specified_model}")

        # è°ƒç”¨æ¨¡å‹é€‰æ‹©å™¨
        try:
            selection_result = await select_best_model(
                df, candidate_models, forecast_horizon, n_windows=3, min_train_size=60
            )

            best_model = selection_result["best_model"]
            baseline = selection_result["baseline"]
            model_comparison = selection_result["metrics"]
            is_better_than_baseline = selection_result["is_better_than_baseline"]

            print(f"[ModelSelection] é€‰æ‹©çš„æœ€ä½³æ¨¡å‹: {best_model}")
            print(f"[ModelSelection] Baseline: {baseline}")
            print(f"[ModelSelection] ç”¨æˆ·æŒ‡å®šæ¨¡å‹: {user_specified_model}")

            # ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„æ¨¡å‹å¹¶ç”Ÿæˆè§£é‡Šä¿¡æ¯
            model_selection_reason = ""
            enable_baseline_penalty = self.ENABLE_BASELINE_PENALTY

            if not user_specified_model or user_specified_model == "auto":
                print(f"[ModelSelection] è¿›å…¥è‡ªåŠ¨é€‰æ‹©åˆ†æ”¯")
                # ç”¨æˆ·æœªæŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨æœ€ä½³æ¨¡å‹
                final_model = best_model
                print(f"[ModelSelection] æœ€ç»ˆæ¨¡å‹: {final_model}")
                # ç”Ÿæˆè§£é‡Šï¼šæœ€ä½³æ¨¡å‹åœ¨æœ€è¿‘ n_windows ä¸ªæ—¶é—´çª—å£çš„ MAE å‡ä½äº baseline
                best_mae = model_comparison.get(best_model)
                baseline_mae = model_comparison.get(baseline)

                if best_mae is not None and baseline_mae is not None:
                    model_name_upper = best_model.upper()
                    baseline_name = baseline.replace("_", " ").title()
                    if enable_baseline_penalty and best_mae >= baseline_mae:
                        # å¦‚æœå¯ç”¨æƒ©ç½šæœºåˆ¶ä¸”æœ€ä½³æ¨¡å‹ä¸å¦‚ baselineï¼Œä½¿ç”¨ baseline
                        final_model = baseline
                        model_selection_reason = (
                            f"æœ€ä½³æ¨¡å‹ {model_name_upper} åœ¨æœ€è¿‘ 3 ä¸ªæ—¶é—´çª—å£çš„ MAE ({best_mae:.4f}) "
                            f"ä¸ä¼˜äº {baseline_name} ({baseline_mae:.4f})ï¼Œå·²è‡ªåŠ¨é™çº§ä¸º {baseline_name}"
                        )
                    else:
                        model_selection_reason = (
                            f"{model_name_upper} åœ¨æœ€è¿‘ 3 ä¸ªæ—¶é—´çª—å£çš„ MAE ({best_mae:.4f}) "
                            f"å‡ä½äº {baseline_name} ({baseline_mae:.4f})"
                        )
                else:
                    model_selection_reason = (
                        f"è‡ªåŠ¨é€‰æ‹© {best_model.upper()} ä½œä¸ºæœ€ä½³æ¨¡å‹"
                    )
            else:
                # ç”¨æˆ·æŒ‡å®šäº†æ¨¡å‹
                print(
                    f"[ModelSelection] è¿›å…¥ç”¨æˆ·æŒ‡å®šæ¨¡å‹åˆ†æ”¯ï¼Œç”¨æˆ·æŒ‡å®š: {user_specified_model}"
                )
                user_model_mae = model_comparison.get(user_specified_model)
                baseline_mae = model_comparison.get(baseline)

                # æ ¹æ®å¼€å…³å†³å®šæ˜¯å¦å¯ç”¨ baseline æƒ©ç½šæœºåˆ¶
                if enable_baseline_penalty and (
                    user_model_mae is not None
                    and baseline_mae is not None
                    and user_model_mae >= baseline_mae
                ):
                    # å¯ç”¨æƒ©ç½šæœºåˆ¶ï¼šå¦‚æœç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹ MAE >= baselineï¼Œåˆ™é™çº§ä¸º baseline
                    final_model = baseline
                    user_model_name = user_specified_model.upper()
                    baseline_name = baseline.replace("_", " ").title()
                    model_selection_reason = (
                        f"ç”¨æˆ·æŒ‡å®šæ¨¡å‹ {user_model_name} åœ¨å†å²å›æµ‹ä¸­ä¸ä¼˜äºåŸºçº¿ "
                        f"({user_model_mae:.4f} >= {baseline_mae:.4f})ï¼Œå·²è‡ªåŠ¨é™çº§ä¸º {baseline_name}"
                    )
                else:
                    # ç¦ç”¨æƒ©ç½šæœºåˆ¶æˆ–ç”¨æˆ·æ¨¡å‹ä¼˜äº baselineï¼šä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹
                    final_model = user_specified_model
                    user_model_name = user_specified_model.upper()
                    if user_model_mae is not None:
                        if (
                            not enable_baseline_penalty
                            and baseline_mae is not None
                            and user_model_mae >= baseline_mae
                        ):
                            # ç¦ç”¨æƒ©ç½šæœºåˆ¶ä½†ç”¨æˆ·æ¨¡å‹ä¸å¦‚ baseline
                            model_selection_reason = (
                                f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ {user_model_name} æ¨¡å‹ "
                                f"(å†å²å›æµ‹ MAE: {user_model_mae:.4f}ï¼Œbaseline: {baseline_mae:.4f})"
                            )
                        else:
                            model_selection_reason = (
                                f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ {user_model_name} æ¨¡å‹ "
                                f"(å†å²å›æµ‹ MAE: {user_model_mae:.4f})"
                            )
                    else:
                        model_selection_reason = (
                            f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ {user_model_name} æ¨¡å‹"
                        )

            # å‘é€æ¨¡å‹é€‰æ‹©ä¿¡æ¯
            await self._emit_event(
                event_queue,
                message,
                {
                    "type": "model_selection",
                    "selected_model": final_model,
                    "best_model": best_model,
                    "baseline": baseline,
                    "model_comparison": model_comparison,
                    "is_better_than_baseline": is_better_than_baseline,
                    "user_specified_model": user_specified_model,
                    "model_selection_reason": model_selection_reason,
                },
            )

            # ä¿å­˜æ¨¡å‹é€‰æ‹©ä¿¡æ¯åˆ° Message
            message.save_model_selection(
                final_model, model_comparison, is_better_than_baseline
            )

            # ä¿å­˜æ¨¡å‹é€‰æ‹©åŸå› 
            message.save_model_selection_reason(model_selection_reason)

            print(f"[ModelSelection] æœ€ç»ˆç¡®å®šçš„æ¨¡å‹: {final_model}")
            message.update_step_detail(
                5, "running", f"è®­ç»ƒ {final_model.upper()} æ¨¡å‹..."
            )

        except Exception as e:
            # å¦‚æœæ¨¡å‹é€‰æ‹©å¤±è´¥ï¼Œä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹æˆ–é»˜è®¤æ¨¡å‹
            print(f"[ModelSelection] æ¨¡å‹é€‰æ‹©å¤±è´¥: {e}")
            final_model = user_specified_model or "prophet"
            model_comparison = {}
            is_better_than_baseline = False

            # ç”Ÿæˆå¤±è´¥æ—¶çš„è§£é‡Šä¿¡æ¯
            if user_specified_model:
                model_selection_reason = f"æ¨¡å‹é€‰æ‹©è¿‡ç¨‹å‡ºç°é”™è¯¯ï¼Œä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ {user_specified_model.upper()} æ¨¡å‹"
            else:
                model_selection_reason = (
                    f"æ¨¡å‹é€‰æ‹©è¿‡ç¨‹å‡ºç°é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤çš„ {final_model.upper()} æ¨¡å‹"
                )

            await self._emit_event(
                event_queue,
                message,
                {
                    "type": "model_selection",
                    "selected_model": final_model,
                    "best_model": final_model,
                    "baseline": "seasonal_naive",
                    "model_comparison": model_comparison,
                    "is_better_than_baseline": is_better_than_baseline,
                    "user_specified_model": user_specified_model,
                    "selection_failed": True,
                    "error": str(e),
                    "model_selection_reason": model_selection_reason,
                },
            )

            # ä¿å­˜æ¨¡å‹é€‰æ‹©åŸå› 
            message.save_model_selection_reason(model_selection_reason)

        prophet_params = await recommend_forecast_params(
            self.sentiment_agent, emotion_result or {}, features
        )

        # åªå¯¹æœ€ç»ˆé€‰å®šçš„æ¨¡å‹è°ƒç”¨ä¸€æ¬¡ run_forecast
        forecast_result = await run_forecast(
            df, intent.forecast_model, max(forecast_horizon, 1), prophet_params
        )

        # ä¿å­˜å¹¶å‘é€é¢„æµ‹ç»“æœï¼ˆforecast_result æ˜¯ ForecastResult å¯¹è±¡ï¼‰
        full_points = original_points + forecast_result.points
        prediction_start = (
            forecast_result.points[0].date if forecast_result.points else ""
        )
        message.save_time_series_full(full_points, prediction_start)

        await self._emit_event(
            event_queue,
            message,
            {
                "type": "data",
                "data_type": "time_series_full",
                "data": [p.model_dump() for p in full_points],
                "prediction_start_day": prediction_start,
            },
        )

        metrics = forecast_result.metrics
        metrics_dict = {"mae": metrics.mae}
        if metrics.rmse:
            metrics_dict["rmse"] = metrics.rmse
        metrics_info = f"MAE: {metrics.mae}" + (
            f", RMSE: {metrics.rmse}" if metrics.rmse else ""
        )
        await self._emit_event(
            event_queue,
            message,
            {"type": "step_complete", "step": 5, "data": {"metrics": metrics_dict}},
        )
        message.update_step_detail(5, "completed", f"é¢„æµ‹å®Œæˆ ({metrics_info})")

        # ä¿å­˜æ¨¡å‹åç§°åˆ° MessageDataï¼ˆä½¿ç”¨æœ€ç»ˆé€‰å®šçš„æ¨¡å‹ï¼‰
        message.save_model_name(final_model)

        # === Step 6: æŠ¥å‘Šç”Ÿæˆï¼ˆæµå¼ï¼‰ ===
        await self._emit_event(
            event_queue,
            message,
            {"type": "step_start", "step": 6, "step_name": "æŠ¥å‘Šç”Ÿæˆ"},
        )
        message.update_step_detail(6, "running", "ç”Ÿæˆåˆ†ææŠ¥å‘Š...")

        # å°† ForecastResult è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä¾›æŠ¥å‘Šç”Ÿæˆä½¿ç”¨
        forecast_dict = {
            "forecast": [
                {"date": p.date, "value": p.value} for p in forecast_result.points
            ],
            "metrics": metrics_dict,
            "model": forecast_result.model,
        }

        report_content = await self._step_report_streaming(
            user_input,
            features,
            forecast_dict,
            emotion_result or {},
            conversation_history,
            event_queue,
            message,
        )

        message.save_conclusion(report_content)
        await self._emit_event(
            event_queue, message, {"type": "step_complete", "step": 6, "data": {}}
        )
        message.update_step_detail(6, "completed", "æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

    # ========== èŠå¤©æµç¨‹ï¼ˆæµå¼ï¼‰ ==========

    async def _execute_chat_streaming(
        self,
        message: Message,
        _session: Session,  # ä¿ç•™å‚æ•°ä»¥ä¿æŒæ¥å£ä¸€è‡´æ€§
        user_input: str,
        intent: UnifiedIntent,
        stock_match: Optional[StockMatchResult],
        keywords: ResolvedKeywords,
        conversation_history: List[dict],
        event_queue: asyncio.Queue | None,
    ):
        """æµå¼èŠå¤©æµç¨‹"""
        step_num = 3 if intent.stock_mention else 2

        # === æ•°æ®è·å– ===
        await self._emit_event(
            event_queue,
            message,
            {"type": "step_start", "step": step_num, "step_name": "ä¿¡æ¯è·å–"},
        )
        message.update_step_detail(step_num, "running", "è·å–ç›¸å…³ä¿¡æ¯...")

        tasks = []
        task_names = []

        if intent.enable_rag:
            rag_available = await check_rag_availability()
            if rag_available:
                tasks.append(
                    fetch_rag_reports(self.rag_searcher, keywords.rag_keywords)
                )
                task_names.append("rag")

        if intent.enable_search:
            tasks.append(search_web(keywords.search_keywords, intent.history_days))
            task_names.append("search")

        if intent.enable_domain_info:
            stock_code = (
                stock_match.stock_info.stock_code
                if stock_match and stock_match.stock_info
                else ""
            )
            tasks.append(fetch_domain_news(stock_code, keywords.domain_keywords))
            task_names.append("domain")

        results = {}
        if tasks:
            task_results = await asyncio.gather(*tasks, return_exceptions=True)
            for name, result in zip(task_names, task_results):
                if not isinstance(result, Exception):
                    results[name] = result

        await self._emit_event(
            event_queue,
            message,
            {
                "type": "step_complete",
                "step": step_num,
                "data": {"sources": list(results.keys())},
            },
        )
        message.update_step_detail(
            step_num, "completed", f"è·å–å®Œæˆ: {list(results.keys())}"
        )

        # === ç”Ÿæˆå›ç­”ï¼ˆæµå¼ï¼‰ ===
        step_num += 1
        await self._emit_event(
            event_queue,
            message,
            {"type": "step_start", "step": step_num, "step_name": "ç”Ÿæˆå›ç­”"},
        )
        message.update_step_detail(step_num, "running", "ç”Ÿæˆå›ç­”...")

        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []

        if "rag" in results and results["rag"]:
            context_parts.append("=== ç ”æŠ¥å†…å®¹ ===")
            for source in results["rag"][:5]:
                context_parts.append(
                    f"[{source.filename} ç¬¬{source.page}é¡µ]: {source.content_snippet}"
                )

        if "search" in results and results["search"]:
            context_parts.append("\n=== ç½‘ç»œæœç´¢ ===")
            for item in results["search"][:5]:
                context_parts.append(
                    f"[{item.get('title', '')}]({item.get('url', '')}): {item.get('content', '')[:100]}"
                )

        if "domain" in results and results["domain"]:
            context_parts.append("\n=== å³æ—¶æ–°é—» ===")
            for item in results["domain"][:5]:
                title = item.get("title", "")
                url = item.get("url", "")
                content = item.get("content", "")[:100]
                if url:
                    context_parts.append(f"[{title}]({url}): {content}")
                else:
                    context_parts.append(f"- {title}: {content}")

        context = "\n".join(context_parts) if context_parts else ""

        # æµå¼ç”Ÿæˆå›ç­”
        answer = await self._step_chat_streaming(
            user_input, conversation_history, context, event_queue, message
        )

        message.save_conclusion(answer)

        if "rag" in results:
            message.save_rag_sources(results["rag"])

        await self._emit_event(
            event_queue,
            message,
            {"type": "step_complete", "step": step_num, "data": {}},
        )
        message.update_step_detail(step_num, "completed", "å›ç­”å®Œæˆ")

    # ========== æµå¼æŠ¥å‘Šç”Ÿæˆ ==========

    async def _step_report_streaming(
        self,
        user_input: str,
        features: Dict,
        forecast_result: Dict,
        emotion_result: Dict,
        conversation_history: List[dict],
        event_queue: asyncio.Queue | None,
        message: Message,
    ) -> str:
        """æµå¼æŠ¥å‘Šç”Ÿæˆ"""
        loop = asyncio.get_running_loop()
        content_queue: asyncio.Queue = asyncio.Queue()

        def run_in_thread():
            def on_chunk(chunk: str):
                loop.call_soon_threadsafe(content_queue.put_nowait, ("chunk", chunk))

            content = self.report_agent.generate_streaming(
                user_input,
                features,
                forecast_result,
                emotion_result,
                conversation_history,
                on_chunk,
            )
            loop.call_soon_threadsafe(content_queue.put_nowait, ("done", content))

        future = loop.run_in_executor(None, run_in_thread)

        full_content = ""
        while True:
            try:
                event_type, data = await asyncio.wait_for(
                    content_queue.get(), timeout=120.0
                )

                if event_type == "chunk":
                    full_content += data
                    await self._emit_event(
                        event_queue,
                        message,
                        {"type": "report_chunk", "content": full_content},
                    )
                elif event_type == "done":
                    full_content = data
                    break
            except asyncio.TimeoutError:
                break

        await future

        return full_content

    # ========== æµå¼æƒ…ç»ªåˆ†æ ==========

    async def _step_sentiment_streaming(
        self,
        news_items: List[SummarizedNewsItem],
        event_queue: asyncio.Queue | None,
        message: Message,
    ) -> Dict[str, Any]:
        """æµå¼æƒ…ç»ªåˆ†æ"""
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        news_list = (
            [
                {
                    "title": n.summarized_title,
                    "content": n.summarized_content,
                    "source_name": n.source_name,
                    "source_type": n.source_type,
                }
                for n in news_items
            ]
            if news_items
            else []
        )

        if not news_list:
            # æ— æ–°é—»æ•°æ®ï¼Œè¿”å›é»˜è®¤å€¼
            default_desc = "æ— æ–°é—»æ•°æ®ï¼Œé»˜è®¤ä¸­æ€§æƒ…ç»ª"
            await self._emit_event(
                event_queue,
                message,
                {
                    "type": "data",
                    "data_type": "emotion",
                    "data": {"score": 0.0, "description": default_desc},
                },
            )
            return {"score": 0.0, "description": default_desc}

        loop = asyncio.get_running_loop()
        content_queue: asyncio.Queue = asyncio.Queue()
        result_holder = {"result": None}

        def run_in_thread():
            def on_chunk(chunk: str):
                loop.call_soon_threadsafe(content_queue.put_nowait, ("chunk", chunk))

            result = self.sentiment_agent.analyze_streaming(news_list, on_chunk)
            result_holder["result"] = result
            loop.call_soon_threadsafe(content_queue.put_nowait, ("done", None))

        future = loop.run_in_executor(None, run_in_thread)

        # å®æ—¶å‘é€æƒ…ç»ªæè¿°
        description_buffer = ""
        score_sent = False

        while True:
            try:
                event_type, data = await asyncio.wait_for(
                    content_queue.get(), timeout=60.0
                )

                if event_type == "chunk":
                    description_buffer += data
                    # æµå¼å‘é€ï¼ˆscore å…ˆè®¾ä¸º 0ï¼Œç­‰å®Œæˆåæ›´æ–°ï¼‰
                    if not score_sent:
                        score_sent = True
                    await self._emit_event(
                        event_queue,
                        message,
                        {"type": "emotion_chunk", "content": description_buffer},
                    )
                elif event_type == "done":
                    break
            except asyncio.TimeoutError:
                break

        await future

        # è·å–æœ€ç»ˆç»“æœ
        result = result_holder["result"] or {
            "score": 0.0,
            "description": description_buffer or "ä¸­æ€§æƒ…ç»ª",
        }

        # å‘é€æœ€ç»ˆæƒ…ç»ªæ•°æ®
        await self._emit_event(
            event_queue,
            message,
            {
                "type": "data",
                "data_type": "emotion",
                "data": {
                    "score": result["score"],
                    "description": result["description"],
                },
            },
        )

        return result

    # ========== æµå¼èŠå¤©ç”Ÿæˆ ==========

    async def _step_chat_streaming(
        self,
        user_input: str,
        conversation_history: List[dict],
        context: str,
        event_queue: asyncio.Queue | None,
        message: Message,
    ) -> str:
        """æµå¼èŠå¤©ç”Ÿæˆ"""
        loop = asyncio.get_running_loop()
        content_queue: asyncio.Queue = asyncio.Queue()

        def run_in_thread():
            gen = self.intent_agent.generate_chat_response(
                user_input, conversation_history, context, stream=True
            )
            full = ""
            for chunk in gen:
                full += chunk
                loop.call_soon_threadsafe(content_queue.put_nowait, ("chunk", full))
            loop.call_soon_threadsafe(content_queue.put_nowait, ("done", full))

        future = loop.run_in_executor(None, run_in_thread)

        full_content = ""
        while True:
            try:
                event_type, data = await asyncio.wait_for(
                    content_queue.get(), timeout=120.0
                )

                if event_type == "chunk":
                    full_content = data
                    await self._emit_event(
                        event_queue,
                        message,
                        {"type": "chat_chunk", "content": full_content},
                    )
                elif event_type == "done":
                    full_content = data
                    break
            except asyncio.TimeoutError:
                break

        await future
        return full_content

    # ========== è¾…åŠ©æ–¹æ³• ==========

    def _update_stream_status(self, message: Message, status: str):
        """æ›´æ–°æµå¼çŠ¶æ€"""
        data = message.get()
        if data:
            data.stream_status = status
            message._save(data)

    async def _emit_event(
        self, event_queue: asyncio.Queue | None, message: Message, event: Dict
    ):
        """å‘é€äº‹ä»¶åˆ°é˜Ÿåˆ—ã€PubSub å’Œ Stream"""

        # 1. å‘é€åˆ°æœ¬åœ°é˜Ÿåˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if event_queue:
            await event_queue.put(event)

        try:
            # 2. å³æ—¶å‘å¸ƒåˆ° PubSub
            channel = f"stream:{message.message_id}"
            json_payload = json.dumps(event)
            self.redis.publish(channel, json_payload)

            # 3. æŒä¹…åŒ–åˆ° Streamï¼ˆä¾›æ–­ç‚¹ç»­ä¼ ä½¿ç”¨ï¼‰
            stream_key = f"stream-events:{message.message_id}"
            self.redis.xadd(
                stream_key, {"data": json_payload}, maxlen=1000, approximate=True
            )
            self.redis.expire(stream_key, 86400)  # 24å°æ—¶ TTL

        except Exception as e:
            print(f"[StreamingTask] Event storage error: {e}")

    async def _emit_error(
        self, event_queue: asyncio.Queue | None, message: Message, error_msg: str
    ):
        """å‘é€é”™è¯¯äº‹ä»¶"""
        await self._emit_event(
            event_queue, message, {"type": "error", "message": error_msg}
        )

    async def _emit_done(self, event_queue: asyncio.Queue | None, message: Message):
        """å‘é€å®Œæˆäº‹ä»¶"""
        await self._emit_event(
            event_queue, message, {"type": "done", "completed": True}
        )


# å•ä¾‹
_streaming_processor: Optional[StreamingTaskProcessor] = None


def get_streaming_processor() -> StreamingTaskProcessor:
    """è·å–æµå¼ä»»åŠ¡å¤„ç†å™¨å•ä¾‹"""
    global _streaming_processor
    if _streaming_processor is None:
        _streaming_processor = StreamingTaskProcessor()
    return _streaming_processor
