{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6c1149",
   "metadata": {},
   "source": [
    "# é‡‘èæ•°æ®åˆ†æç®¡é“ Demo\n",
    "\n",
    "## æ¶æ„æ¦‚è¿°\n",
    "\n",
    "æœ¬Demoå®ç°ä¸€ä¸ªæ™ºèƒ½é‡‘èæ•°æ®åˆ†æç®¡é“ï¼ŒåŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š\n",
    "\n",
    "1. **ç”¨æˆ·éœ€æ±‚è§£æ Agent** - ä½¿ç”¨ DeepSeek API å°†è‡ªç„¶è¯­è¨€éœ€æ±‚ç¿»è¯‘ä¸º AKShare æ•°æ®è·å–ä»£ç \n",
    "2. **æ•°æ®è·å–å±‚** - ä½¿ç”¨ AKShare è·å–é‡‘èæ•°æ®\n",
    "3. **æ•°æ®å¤„ç†å±‚** - å°†æ•°æ®è½¬æ¢ä¸º TimeCopilot æ‰€éœ€æ ¼å¼\n",
    "4. **åˆ†æ/é¢„æµ‹å±‚** - ä½¿ç”¨ TimeCopilot è¿›è¡Œæ—¶åºåˆ†æä¸é¢„æµ‹\n",
    "5. **ç»“æœè¾“å‡º** - è¿”å›åˆ†æå»ºè®®ã€é¢„æµ‹æ›²çº¿å’Œæ€»ç»“\n",
    "\n",
    "### ä¾èµ–å®‰è£…\n",
    "```bash\n",
    "pip install akshare timecopilot openai pandas matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170e443",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "557c53d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…ä¾èµ–ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "# !pip install akshare timecopilot openai pandas matplotlib --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f518ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# API Keys é…ç½®\n",
    "# è¯·æ›¿æ¢ä¸ºä½ çš„å®é™… API Key\n",
    "DEEPSEEK_API_KEY = os.environ.get(\"DEEPSEEK_API_KEY\", \"")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")  # TimeCopilot éœ€è¦\n",
    "\n",
    "# è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8220f",
   "metadata": {},
   "source": [
    "## 2. AKShare æ•°æ®æ¥å£æ˜ å°„\n",
    "\n",
    "å®šä¹‰ AKShare å¸¸ç”¨æ¥å£çš„æ˜ å°„å…³ç³»ï¼Œä¾› Agent è§£æä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5799d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKShare æ¥å£æ–‡æ¡£ï¼ˆä¾› Agent å‚è€ƒï¼‰\n",
    "AKSHARE_API_DOCS = \"\"\"\n",
    "## AKShare å¸¸ç”¨æ•°æ®æ¥å£\n",
    "\n",
    "### è‚¡ç¥¨æ•°æ®\n",
    "1. **stock_zh_a_hist** - Aè‚¡å†å²è¡Œæƒ…æ•°æ®\n",
    "   - å‚æ•°: symbol(è‚¡ç¥¨ä»£ç å¦‚\"000001\"), period(\"daily\"/\"weekly\"/\"monthly\"), \n",
    "           start_date(\"YYYYMMDD\"), end_date(\"YYYYMMDD\"), adjust(\"qfq\"/\"hfq\"/\"\")\n",
    "   - è¿”å›: æ—¥æœŸ,å¼€ç›˜,æ”¶ç›˜,æœ€é«˜,æœ€ä½,æˆäº¤é‡,æˆäº¤é¢,æŒ¯å¹…,æ¶¨è·Œå¹…,æ¶¨è·Œé¢,æ¢æ‰‹ç‡\n",
    "\n",
    "2. **stock_zh_a_spot_em** - Aè‚¡å®æ—¶è¡Œæƒ…\n",
    "   - å‚æ•°: æ— \n",
    "   - è¿”å›: æ‰€æœ‰Aè‚¡å®æ—¶è¡Œæƒ…æ•°æ®\n",
    "\n",
    "### æŒ‡æ•°æ•°æ®\n",
    "3. **stock_zh_index_daily_em** - è‚¡ç¥¨æŒ‡æ•°å†å²æ•°æ®\n",
    "   - å‚æ•°: symbol(æŒ‡æ•°ä»£ç å¦‚\"sh000001\"ä¸Šè¯æŒ‡æ•°, \"sz399001\"æ·±è¯æˆæŒ‡, \"sz399006\"åˆ›ä¸šæ¿æŒ‡)\n",
    "   - è¿”å›: date,open,close,high,low,volume,amount\n",
    "\n",
    "4. **index_zh_a_hist** - æŒ‡æ•°å†å²è¡Œæƒ…(å¸¦æ—¥æœŸèŒƒå›´)\n",
    "   - å‚æ•°: symbol, period, start_date, end_date\n",
    "\n",
    "### åŸºé‡‘æ•°æ®\n",
    "5. **fund_etf_hist_em** - ETFåŸºé‡‘å†å²æ•°æ®\n",
    "   - å‚æ•°: symbol(ETFä»£ç ), period, start_date, end_date, adjust\n",
    "\n",
    "6. **fund_open_fund_info_em** - å¼€æ”¾å¼åŸºé‡‘ä¿¡æ¯\n",
    "   - å‚æ•°: symbol(åŸºé‡‘ä»£ç ), indicator(\"å•ä½å‡€å€¼èµ°åŠ¿\"/\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\")\n",
    "\n",
    "### æœŸè´§æ•°æ®\n",
    "7. **futures_main_sina** - æœŸè´§ä¸»åŠ›è¿ç»­åˆçº¦\n",
    "   - å‚æ•°: symbol(æœŸè´§ä»£ç å¦‚\"RB0\"èºçº¹é’¢)\n",
    "\n",
    "### å®è§‚ç»æµæ•°æ®\n",
    "8. **macro_china_gdp** - ä¸­å›½GDPæ•°æ®\n",
    "9. **macro_china_cpi** - ä¸­å›½CPIæ•°æ®\n",
    "10. **macro_china_pmi** - ä¸­å›½PMIæ•°æ®\n",
    "\n",
    "### å¸¸ç”¨è‚¡ç¥¨ä»£ç ç¤ºä¾‹\n",
    "- å¹³å®‰é“¶è¡Œ: 000001\n",
    "- è´µå·èŒ…å°: 600519\n",
    "- æ¯”äºšè¿ª: 002594\n",
    "- å®å¾·æ—¶ä»£: 300750\n",
    "\n",
    "### å¸¸ç”¨æŒ‡æ•°ä»£ç \n",
    "- ä¸Šè¯æŒ‡æ•°: sh000001 æˆ– 000001\n",
    "- æ·±è¯æˆæŒ‡: sz399001 æˆ– 399001\n",
    "- åˆ›ä¸šæ¿æŒ‡: sz399006 æˆ– 399006\n",
    "- æ²ªæ·±300: sh000300 æˆ– 000300\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dfbb77",
   "metadata": {},
   "source": [
    "## 3. DeepSeek Agent - éœ€æ±‚è§£æå™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113a9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class DataRequestAgent:\n",
    "    \"\"\"ä½¿ç”¨ DeepSeek API å°†ç”¨æˆ·è‡ªç„¶è¯­è¨€éœ€æ±‚è½¬æ¢ä¸º AKShare è°ƒç”¨\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://api.deepseek.com\"  # DeepSeek API ç«¯ç‚¹\n",
    "        )\n",
    "        self.model = \"deepseek-chat\"  # æˆ– \"deepseek-coder\" ç”¨äºä»£ç ç”Ÿæˆ\n",
    "    \n",
    "    def parse_request(self, user_query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        è§£æç”¨æˆ·éœ€æ±‚ï¼Œè¿”å›æ•°æ®è·å–é…ç½®\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                \"api_function\": \"stock_zh_a_hist\",\n",
    "                \"params\": {...},\n",
    "                \"data_type\": \"stock\",\n",
    "                \"analysis_type\": \"forecast\" / \"analysis\",\n",
    "                \"forecast_horizon\": 30,\n",
    "                \"user_question\": \"åŸå§‹é—®é¢˜ç”¨äºåç»­å›ç­”\"\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªé‡‘èæ•°æ®åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€éœ€æ±‚è½¬æ¢ä¸º AKShare æ•°æ®è·å–é…ç½®ã€‚\n",
    "\n",
    "{AKSHARE_API_DOCS}\n",
    "\n",
    "è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œè¿”å›ä¸€ä¸ª JSON æ ¼å¼çš„é…ç½®ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n",
    "1. api_function: AKShare å‡½æ•°å\n",
    "2. params: å‡½æ•°å‚æ•°å­—å…¸\n",
    "3. data_type: æ•°æ®ç±»å‹ (stock/index/fund/futures/macro)\n",
    "4. analysis_type: åˆ†æç±»å‹ (forecasté¢„æµ‹/analysisåˆ†æ)\n",
    "5. forecast_horizon: é¢„æµ‹å‘¨æœŸ(å¤©æ•°)ï¼Œå¦‚æœæ˜¯é¢„æµ‹ä»»åŠ¡\n",
    "6. target_column: ç›®æ ‡åˆ—åï¼ˆé€šå¸¸æ˜¯\"æ”¶ç›˜\"æˆ–\"close\"ï¼‰\n",
    "7. user_question: ç”¨æˆ·åŸå§‹é—®é¢˜çš„æ ¸å¿ƒè¯‰æ±‚\n",
    "\n",
    "æ³¨æ„ï¼š\n",
    "- å¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šæ—¥æœŸèŒƒå›´ï¼Œé»˜è®¤è·å–æœ€è¿‘1å¹´çš„æ•°æ®\n",
    "- æ—¥æœŸæ ¼å¼ä¸º YYYYMMDD\n",
    "- åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–è§£é‡Š\n",
    "\n",
    "ä»Šå¤©æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_query}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        return result\n",
    "    \n",
    "    def generate_summary(self, forecast_result: Dict, original_query: str) -> str:\n",
    "        \"\"\"æ ¹æ®é¢„æµ‹ç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€æ€»ç»“\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ç”¨æˆ·åŸå§‹é—®é¢˜: {original_query}\n",
    "\n",
    "é¢„æµ‹ç»“æœ:\n",
    "- é€‰ç”¨æ¨¡å‹: {forecast_result.get('selected_model', 'N/A')}\n",
    "- æ¨¡å‹é€‰æ‹©åŸå› : {forecast_result.get('reason_for_selection', 'N/A')}\n",
    "- æ—¶åºç‰¹å¾åˆ†æ: {forecast_result.get('tsfeatures_analysis', 'N/A')}\n",
    "- é¢„æµ‹åˆ†æ: {forecast_result.get('forecast_analysis', 'N/A')}\n",
    "- é¢„æµ‹å€¼: {forecast_result.get('forecast', [])[:10]}... (å‰10ä¸ª)\n",
    "\n",
    "è¯·ç”¨ä¸­æ–‡ä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä¸ªç®€æ´ä¸“ä¸šçš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«:\n",
    "1. æ•°æ®ç‰¹å¾æ¦‚è¿°\n",
    "2. æ¨¡å‹é€‰æ‹©è¯´æ˜\n",
    "3. é¢„æµ‹è¶‹åŠ¿æ€»ç»“\n",
    "4. æŠ•èµ„å»ºè®®ï¼ˆé£é™©æç¤ºï¼‰\n",
    "\n",
    "æ³¨æ„: ä¿æŒå®¢è§‚ï¼Œæ·»åŠ å¿…è¦çš„é£é™©æç¤ºã€‚\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c737b5",
   "metadata": {},
   "source": [
    "## 4. æ•°æ®è·å–å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f4214bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "\n",
    "class DataFetcher:\n",
    "    \"\"\"ä½¿ç”¨ AKShare è·å–é‡‘èæ•°æ®\"\"\"\n",
    "    \n",
    "    # æ”¯æŒçš„ API å‡½æ•°æ˜ å°„\n",
    "    API_MAPPING = {\n",
    "        \"stock_zh_a_hist\": ak.stock_zh_a_hist,\n",
    "        \"stock_zh_a_spot_em\": ak.stock_zh_a_spot_em,\n",
    "        \"stock_zh_index_daily_em\": ak.stock_zh_index_daily_em,\n",
    "        \"index_zh_a_hist\": ak.index_zh_a_hist,\n",
    "        \"fund_etf_hist_em\": ak.fund_etf_hist_em,\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def fetch_data(cls, config: Dict[str, Any]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        æ ¹æ®é…ç½®è·å–æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            config: Agent è§£æåçš„é…ç½®\n",
    "            \n",
    "        Returns:\n",
    "            pandas DataFrame\n",
    "        \"\"\"\n",
    "        api_function = config.get(\"api_function\")\n",
    "        params = config.get(\"params\", {})\n",
    "        \n",
    "        if api_function not in cls.API_MAPPING:\n",
    "            raise ValueError(f\"ä¸æ”¯æŒçš„ API å‡½æ•°: {api_function}\")\n",
    "        \n",
    "        func = cls.API_MAPPING[api_function]\n",
    "        \n",
    "        try:\n",
    "            df = func(**params)\n",
    "            print(f\"âœ… æˆåŠŸè·å–æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è·å–æ•°æ®å¤±è´¥: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c8754",
   "metadata": {},
   "source": [
    "## 5. æ•°æ®è½¬æ¢å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5433c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer:\n",
    "    \"\"\"å°† AKShare æ•°æ®è½¬æ¢ä¸º TimeCopilot æ‰€éœ€æ ¼å¼\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def transform_for_timecopilot(\n",
    "        df: pd.DataFrame, \n",
    "        config: Dict[str, Any]\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        è½¬æ¢æ•°æ®æ ¼å¼\n",
    "        \n",
    "        TimeCopilot è¦æ±‚çš„æ ¼å¼:\n",
    "        - unique_id: æ—¶åºå”¯ä¸€æ ‡è¯† (string)\n",
    "        - ds: æ—¥æœŸåˆ— (datetime)\n",
    "        - y: ç›®æ ‡å˜é‡ (float)\n",
    "        \"\"\"\n",
    "        \n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        # æ£€æµ‹æ—¥æœŸåˆ—\n",
    "        date_columns = [\"æ—¥æœŸ\", \"date\", \"Date\", \"æ—¶é—´\", \"time\"]\n",
    "        date_col = None\n",
    "        for col in date_columns:\n",
    "            if col in df_copy.columns:\n",
    "                date_col = col\n",
    "                break\n",
    "        \n",
    "        if date_col is None:\n",
    "            # å°è¯•ä½¿ç”¨ç´¢å¼•ä½œä¸ºæ—¥æœŸ\n",
    "            if isinstance(df_copy.index, pd.DatetimeIndex):\n",
    "                df_copy = df_copy.reset_index()\n",
    "                date_col = df_copy.columns[0]\n",
    "            else:\n",
    "                raise ValueError(\"æœªæ‰¾åˆ°æ—¥æœŸåˆ—\")\n",
    "        \n",
    "        # æ£€æµ‹ç›®æ ‡åˆ—\n",
    "        target_col = config.get(\"target_column\", \"æ”¶ç›˜\")\n",
    "        target_columns = [target_col, \"close\", \"Close\", \"æ”¶ç›˜\", \"æ”¶ç›˜ä»·\"]\n",
    "        y_col = None\n",
    "        for col in target_columns:\n",
    "            if col in df_copy.columns:\n",
    "                y_col = col\n",
    "                break\n",
    "        \n",
    "        if y_col is None:\n",
    "            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°å€¼åˆ—\n",
    "            numeric_cols = df_copy.select_dtypes(include=['float64', 'int64']).columns\n",
    "            if len(numeric_cols) > 0:\n",
    "                y_col = numeric_cols[0]\n",
    "            else:\n",
    "                raise ValueError(\"æœªæ‰¾åˆ°ç›®æ ‡æ•°å€¼åˆ—\")\n",
    "        \n",
    "        # ç”Ÿæˆ unique_id\n",
    "        symbol = config.get(\"params\", {}).get(\"symbol\", \"unknown\")\n",
    "        \n",
    "        # æ„å»º TimeCopilot æ ¼å¼\n",
    "        result = pd.DataFrame({\n",
    "            \"unique_id\": symbol,\n",
    "            \"ds\": pd.to_datetime(df_copy[date_col]),\n",
    "            \"y\": df_copy[y_col].astype(float)\n",
    "        })\n",
    "        \n",
    "        # æ’åºå¹¶å»é‡\n",
    "        result = result.sort_values(\"ds\").drop_duplicates(subset=[\"ds\"]).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"âœ… æ•°æ®è½¬æ¢å®Œæˆ: {len(result)} æ¡è®°å½•\")\n",
    "        print(f\"   æ—¥æœŸèŒƒå›´: {result['ds'].min()} ~ {result['ds'].max()}\")\n",
    "        print(result.head())\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da8931d",
   "metadata": {},
   "source": [
    "## 6. åˆ†æ/é¢„æµ‹å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c0b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timecopilot import TimeCopilot\n",
    "\n",
    "class TimeSeriesAnalyzer:\n",
    "    \"\"\"ä½¿ç”¨ TimeCopilot è¿›è¡Œæ—¶åºåˆ†æå’Œé¢„æµ‹\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_model):\n",
    "        self.tc = TimeCopilot(\n",
    "            llm=llm_model,\n",
    "            retries=3\n",
    "        )\n",
    "    \n",
    "    def forecast(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        horizon: int = 30,\n",
    "        freq: str = \"D\",\n",
    "        query: Optional[str] = None\n",
    "    ) -> Tuple[Any, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        æ‰§è¡Œæ—¶åºé¢„æµ‹\n",
    "        \n",
    "        Args:\n",
    "            df: TimeCopilot æ ¼å¼çš„æ•°æ®\n",
    "            horizon: é¢„æµ‹å‘¨æœŸ\n",
    "            freq: æ•°æ®é¢‘ç‡ (D=æ—¥, W=å‘¨, M=æœˆ)\n",
    "            query: ç”¨æˆ·é—®é¢˜ï¼ˆå¯é€‰ï¼‰\n",
    "            \n",
    "        Returns:\n",
    "            (é¢„æµ‹ç»“æœå¯¹è±¡, é¢„æµ‹DataFrame)\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ”® å¼€å§‹é¢„æµ‹ï¼Œé¢„æµ‹å‘¨æœŸ: {horizon} {freq}\")\n",
    "        \n",
    "        result = self.tc.forecast(\n",
    "            df=df,\n",
    "            freq=freq,\n",
    "            h=horizon,\n",
    "            query=query\n",
    "        )\n",
    "        \n",
    "        return result.output, result.fcst_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_forecast_values(result_output) -> Dict[str, Any]:\n",
    "        \"\"\"æå–é¢„æµ‹ç»“æœçš„å…³é”®ä¿¡æ¯\"\"\"\n",
    "        return {\n",
    "            \"selected_model\": getattr(result_output, 'selected_model', 'N/A'),\n",
    "            \"model_details\": getattr(result_output, 'model_details', 'N/A'),\n",
    "            \"tsfeatures_analysis\": getattr(result_output, 'tsfeatures_analysis', 'N/A'),\n",
    "            \"forecast_analysis\": getattr(result_output, 'forecast_analysis', 'N/A'),\n",
    "            \"reason_for_selection\": getattr(result_output, 'reason_for_selection', 'N/A'),\n",
    "            \"forecast\": getattr(result_output, 'forecast', []),\n",
    "            \"is_better_than_seasonal_naive\": getattr(result_output, 'is_better_than_seasonal_naive', None),\n",
    "            \"cross_validation_results\": getattr(result_output, 'cross_validation_results', []),\n",
    "            \"user_query_response\": getattr(result_output, 'user_query_response', None)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea720130",
   "metadata": {},
   "source": [
    "## 7. å¯è§†åŒ–æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6eb3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    \"\"\"ç»“æœå¯è§†åŒ–\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_forecast(\n",
    "        historical_df: pd.DataFrame,\n",
    "        forecast_df: pd.DataFrame,\n",
    "        title: str = \"æ—¶åºé¢„æµ‹ç»“æœ\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ç»˜åˆ¶å†å²æ•°æ®å’Œé¢„æµ‹ç»“æœ\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        \n",
    "        # ç»˜åˆ¶å†å²æ•°æ®\n",
    "        ax.plot(\n",
    "            historical_df['ds'], \n",
    "            historical_df['y'], \n",
    "            label='å†å²æ•°æ®',\n",
    "            color='blue',\n",
    "            linewidth=1.5\n",
    "        )\n",
    "        \n",
    "        # ç»˜åˆ¶é¢„æµ‹æ•°æ®\n",
    "        if forecast_df is not None and len(forecast_df) > 0:\n",
    "            # è·å–é¢„æµ‹å€¼åˆ—ï¼ˆé€šå¸¸æ˜¯æ¨¡å‹åç§°ï¼‰\n",
    "            value_cols = [c for c in forecast_df.columns if c not in ['unique_id', 'ds']]\n",
    "            if value_cols:\n",
    "                forecast_col = value_cols[0]\n",
    "                ax.plot(\n",
    "                    forecast_df['ds'],\n",
    "                    forecast_df[forecast_col],\n",
    "                    label=f'é¢„æµ‹ ({forecast_col})',\n",
    "                    color='red',\n",
    "                    linewidth=2,\n",
    "                    linestyle='--'\n",
    "                )\n",
    "        \n",
    "        ax.set_title(title, fontsize=14)\n",
    "        ax.set_xlabel('æ—¥æœŸ')\n",
    "        ax.set_ylabel('ä»·æ ¼')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d3098c",
   "metadata": {},
   "source": [
    "## 8. å®Œæ•´ç®¡é“ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be4c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.providers.deepseek import DeepSeekProvider\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "\n",
    "class FinancialDataPipeline:\n",
    "    \"\"\"\n",
    "    é‡‘èæ•°æ®åˆ†æç®¡é“\n",
    "    \n",
    "    å®Œæ•´æµç¨‹:\n",
    "    ç”¨æˆ·éœ€æ±‚ -> Agentè§£æ -> æ•°æ®è·å– -> æ•°æ®è½¬æ¢ -> æ—¶åºåˆ†æ -> ç»“æœè¾“å‡º\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, deepseek_api_key: str, openai_api_key: str):\n",
    "        self.agent = DataRequestAgent(deepseek_api_key)\n",
    "        self.llm_model = OpenAIChatModel(\n",
    "            'deepseek-chat',\n",
    "            provider=DeepSeekProvider(api_key=deepseek_api_key),\n",
    "        )\n",
    "        self.analyzer = TimeSeriesAnalyzer(llm_model=self.llm_model)\n",
    "        \n",
    "        # ç¡®ä¿ç¯å¢ƒå˜é‡è®¾ç½®\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    \n",
    "    def run(self, user_query: str, visualize: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        æ‰§è¡Œå®Œæ•´çš„åˆ†æç®¡é“\n",
    "        \n",
    "        Args:\n",
    "            user_query: ç”¨æˆ·è‡ªç„¶è¯­è¨€éœ€æ±‚\n",
    "            visualize: æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–\n",
    "            \n",
    "        Returns:\n",
    "            {\n",
    "                \"config\": Agentè§£æé…ç½®,\n",
    "                \"raw_data\": åŸå§‹æ•°æ®,\n",
    "                \"transformed_data\": è½¬æ¢åæ•°æ®,\n",
    "                \"forecast_output\": é¢„æµ‹ç»“æœå¯¹è±¡,\n",
    "                \"forecast_df\": é¢„æµ‹DataFrame,\n",
    "                \"forecast_values\": é¢„æµ‹å€¼åˆ—è¡¨,\n",
    "                \"summary\": åˆ†ææ€»ç»“\n",
    "            }\n",
    "        \"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“ ç”¨æˆ·éœ€æ±‚: {user_query}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Step 1: Agent è§£æéœ€æ±‚\n",
    "        print(\"\\nğŸ¤– Step 1: è§£æç”¨æˆ·éœ€æ±‚...\")\n",
    "        config = self.agent.parse_request(user_query)\n",
    "        print(f\"   è§£æç»“æœ: {json.dumps(config, ensure_ascii=False, indent=2)}\")\n",
    "        \n",
    "        # Step 2: è·å–æ•°æ®\n",
    "        print(\"\\nğŸ“Š Step 2: è·å–æ•°æ®...\")\n",
    "        raw_data = DataFetcher.fetch_data(config)\n",
    "        print(raw_data.head())\n",
    "        \n",
    "        # Step 3: è½¬æ¢æ•°æ®\n",
    "        print(\"\\nğŸ”„ Step 3: è½¬æ¢æ•°æ®æ ¼å¼...\")\n",
    "        transformed_data = DataTransformer.transform_for_timecopilot(raw_data, config)\n",
    "        \n",
    "        # Step 4: æ—¶åºåˆ†æ/é¢„æµ‹\n",
    "        print(\"\\nğŸ”® Step 4: æ‰§è¡Œæ—¶åºé¢„æµ‹...\")\n",
    "        forecast_horizon = config.get(\"forecast_horizon\", 30)\n",
    "        forecast_query = config.get(\"user_question\", user_query)\n",
    "        \n",
    "        forecast_output, forecast_df = self.analyzer.forecast(\n",
    "            df=transformed_data,\n",
    "            horizon=forecast_horizon,\n",
    "            freq=\"D\",\n",
    "            query=forecast_query\n",
    "        )\n",
    "        \n",
    "        # æå–é¢„æµ‹å€¼\n",
    "        forecast_values = self.analyzer.extract_forecast_values(forecast_output)\n",
    "        \n",
    "        # Step 5: ç”Ÿæˆæ€»ç»“\n",
    "        print(\"\\nğŸ“‹ Step 5: ç”Ÿæˆåˆ†ææŠ¥å‘Š...\")\n",
    "        summary = self.agent.generate_summary(forecast_values, user_query)\n",
    "        \n",
    "        # Step 6: å¯è§†åŒ–\n",
    "        if visualize:\n",
    "            print(\"\\nğŸ“ˆ Step 6: ç”Ÿæˆå¯è§†åŒ–...\")\n",
    "            symbol = config.get(\"params\", {}).get(\"symbol\", \"\")\n",
    "            Visualizer.plot_forecast(\n",
    "                transformed_data, \n",
    "                forecast_df,\n",
    "                title=f\"{symbol} æ—¶åºé¢„æµ‹ç»“æœ\"\n",
    "            )\n",
    "        \n",
    "        # è¾“å‡ºç»“æœ\n",
    "        result = {\n",
    "            \"config\": config,\n",
    "            \"raw_data\": raw_data,\n",
    "            \"transformed_data\": transformed_data,\n",
    "            \"forecast_output\": forecast_output,\n",
    "            \"forecast_df\": forecast_df,\n",
    "            \"forecast_values\": forecast_values,\n",
    "            \"summary\": summary\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“Š åˆ†ææŠ¥å‘Š\")\n",
    "        print(\"=\"*60)\n",
    "        print(summary)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ecc1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–ç®¡é“\n",
    "# æ³¨æ„: è¯·æ›¿æ¢ä¸ºä½ çš„å®é™… API Key\n",
    "pipeline = FinancialDataPipeline(\n",
    "    deepseek_api_key=DEEPSEEK_API_KEY,\n",
    "    openai_api_key=DEEPSEEK_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7617863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“ ç”¨æˆ·éœ€æ±‚: å¸®æˆ‘åˆ†æä¸€ä¸‹å¹³å®‰é“¶è¡Œ(000001)æœ€è¿‘ä¸€å¹´çš„èµ°åŠ¿ï¼Œæ‰¾å‡ºæœ€å¤§å€¼å’Œæœ€ä½ç‚¹\n",
      "============================================================\n",
      "\n",
      "ğŸ¤– Step 1: è§£æç”¨æˆ·éœ€æ±‚...\n",
      "   è§£æç»“æœ: {\n",
      "  \"api_function\": \"stock_zh_a_hist\",\n",
      "  \"params\": {\n",
      "    \"symbol\": \"000001\",\n",
      "    \"period\": \"daily\",\n",
      "    \"start_date\": \"20250104\",\n",
      "    \"end_date\": \"20260104\",\n",
      "    \"adjust\": \"\"\n",
      "  },\n",
      "  \"data_type\": \"stock\",\n",
      "  \"analysis_type\": \"analysis\",\n",
      "  \"forecast_horizon\": null,\n",
      "  \"target_column\": \"close\",\n",
      "  \"user_question\": \"åˆ†æå¹³å®‰é“¶è¡Œ(000001)æœ€è¿‘ä¸€å¹´çš„èµ°åŠ¿ï¼Œæ‰¾å‡ºæœ€å¤§å€¼å’Œæœ€ä½ç‚¹\"\n",
      "}\n",
      "\n",
      "ğŸ“Š Step 2: è·å–æ•°æ®...\n",
      "âœ… æˆåŠŸè·å–æ•°æ®ï¼Œå…± 241 æ¡è®°å½•\n",
      "           æ—¥æœŸ    è‚¡ç¥¨ä»£ç      å¼€ç›˜     æ”¶ç›˜     æœ€é«˜     æœ€ä½      æˆäº¤é‡           æˆäº¤é¢  \\\n",
      "0  2025-01-06  000001  11.38  11.44  11.48  11.22  1085536  1.234306e+09   \n",
      "1  2025-01-07  000001  11.42  11.51  11.53  11.37   747863  8.583290e+08   \n",
      "2  2025-01-08  000001  11.50  11.50  11.63  11.40  1062386  1.223599e+09   \n",
      "3  2025-01-09  000001  11.50  11.40  11.50  11.35   751483  8.578361e+08   \n",
      "4  2025-01-10  000001  11.40  11.30  11.46  11.28   798134  9.050050e+08   \n",
      "\n",
      "     æŒ¯å¹…   æ¶¨è·Œå¹…   æ¶¨è·Œé¢   æ¢æ‰‹ç‡  \n",
      "0  2.28  0.53  0.06  0.56  \n",
      "1  1.40  0.61  0.07  0.39  \n",
      "2  2.00 -0.09 -0.01  0.55  \n",
      "3  1.30 -0.87 -0.10  0.39  \n",
      "4  1.58 -0.88 -0.10  0.41  \n",
      "\n",
      "ğŸ”„ Step 3: è½¬æ¢æ•°æ®æ ¼å¼...\n",
      "âœ… æ•°æ®è½¬æ¢å®Œæˆ: 241 æ¡è®°å½•\n",
      "   æ—¥æœŸèŒƒå›´: 2025-01-06 00:00:00 ~ 2025-12-31 00:00:00\n",
      "\n",
      "ğŸ”® Step 4: æ‰§è¡Œæ—¶åºé¢„æµ‹...\n",
      "ğŸ”® å¼€å§‹é¢„æµ‹ï¼Œé¢„æµ‹å‘¨æœŸ: None D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 105.08it/s]\n",
      "1it [00:00, 178.38it/s]\n",
      "1it [00:00,  9.60it/s]\n",
      "1it [00:00, 72.93it/s]\n",
      "1it [00:00, 154.16it/s]\n",
      "0it [00:00, ?it/s]16:24:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "1it [00:00,  5.19it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_18192/3306682652.py\", line 2, in <module>\n",
      "    result1 = pipeline.run(\n",
      "              ^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_18192/1484950511.py\", line 65, in run\n",
      "    forecast_output, forecast_df = self.analyzer.forecast(\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_18192/2407188419.py\", line 33, in forecast\n",
      "    result = self.tc.forecast(\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/timecopilot/agent.py\", line 1255, in forecast\n",
      "    return self.analyze(df=df, h=h, freq=freq, seasonality=seasonality, query=query)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/timecopilot/agent.py\", line 1202, in analyze\n",
      "    result = self.forecasting_agent.run_sync(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/agent/abstract.py\", line 372, in run_sync\n",
      "    return _utils.get_event_loop().run_until_complete(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/agent/abstract.py\", line 251, in run\n",
      "    async with self.iter(\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 231, in __aexit__\n",
      "    await self.gen.athrow(typ, value, traceback)\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/agent/__init__.py\", line 678, in iter\n",
      "    async with graph.iter(\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 231, in __aexit__\n",
      "    await self.gen.athrow(typ, value, traceback)\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_graph/beta/graph.py\", line 270, in iter\n",
      "    async with GraphRun[StateT, DepsT, OutputT](\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_graph/beta/graph.py\", line 423, in __aexit__\n",
      "    await self._async_exit_stack.__aexit__(exc_type, exc_val, exc_tb)\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 745, in __aexit__\n",
      "    raise exc_details[1]\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 726, in __aexit__\n",
      "    cb_suppress = cb(*exc_details)\n",
      "                  ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_graph/beta/graph.py\", line 981, in _unwrap_exception_groups\n",
      "    raise exception\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_graph/beta/graph.py\", line 750, in _run_tracked_task\n",
      "    result = await self._run_task(t_)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_graph/beta/graph.py\", line 782, in _run_task\n",
      "    output = await node.call(step_context)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_graph/beta/step.py\", line 253, in _call_node\n",
      "    return await node.run(GraphRunContext(state=ctx.state, deps=ctx.deps))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_agent_graph.py\", line 575, in run\n",
      "    async with self.stream(ctx):\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 217, in __aexit__\n",
      "    await anext(self.gen)\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_agent_graph.py\", line 589, in stream\n",
      "    async for _event in stream:\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_agent_graph.py\", line 715, in _run_stream\n",
      "    async for event in self._events_iterator:\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_agent_graph.py\", line 676, in _run_stream\n",
      "    async for event in self._handle_tool_calls(ctx, tool_calls):\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_agent_graph.py\", line 731, in _handle_tool_calls\n",
      "    async for event in process_tool_calls(\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_agent_graph.py\", line 974, in process_tool_calls\n",
      "    async for event in _call_tools(\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_agent_graph.py\", line 1110, in _call_tools\n",
      "    if event := await handle_call_or_result(coro_or_task=task, index=index):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_agent_graph.py\", line 1073, in handle_call_or_result\n",
      "    (await coro_or_task) if inspect.isawaitable(coro_or_task) else coro_or_task.result()\n",
      "     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/asyncio/futures.py\", line 290, in __await__\n",
      "    return self.result()  # May raise too.\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/home/chenty/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_agent_graph.py\", line 1146, in _call_tool\n",
      "    tool_result = await tool_manager.handle_call(tool_call)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_tool_manager.py\", line 119, in handle_call\n",
      "    return await self._call_function_tool(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_tool_manager.py\", line 252, in _call_function_tool\n",
      "    tool_result = await self._call_tool(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_tool_manager.py\", line 175, in _call_tool\n",
      "    return await self.toolset.call_tool(name, args_dict, ctx, tool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/toolsets/combined.py\", line 90, in call_tool\n",
      "    return await tool.source_toolset.call_tool(name, tool_args, ctx, tool.source_tool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/toolsets/combined.py\", line 90, in call_tool\n",
      "    return await tool.source_toolset.call_tool(name, tool_args, ctx, tool.source_tool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/toolsets/function.py\", line 383, in call_tool\n",
      "    return await tool.call_func(tool_args, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/pydantic_ai/_function_schema.py\", line 52, in call\n",
      "    return await function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/timecopilot/agent.py\", line 949, in cross_validation_tool\n",
      "    eval_df = ctx.deps.evaluate_forecast_df(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/timecopilot/utils/experiment_handler.py\", line 242, in evaluate_forecast_df\n",
      "    eval_df = evaluate(\n",
      "              ^^^^^^^^^\n",
      "  File \"/home/chenty/xiaoyi/.venv/lib/python3.11/site-packages/utilsforecast/evaluation.py\", line 314, in evaluate\n",
      "    result = metric(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "TypeError: mase() got an unexpected keyword argument 'cutoff_col'\n"
     ]
    }
   ],
   "source": [
    "# ç¤ºä¾‹1: è‚¡ç¥¨ä»·æ ¼é¢„æµ‹\n",
    "result1 = pipeline.run(\n",
    "    \"å¸®æˆ‘åˆ†æä¸€ä¸‹å¹³å®‰é“¶è¡Œ(000001)æœ€è¿‘ä¸€å¹´çš„èµ°åŠ¿ï¼Œæ‰¾å‡ºæœ€å¤§å€¼å’Œæœ€ä½ç‚¹\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c142d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(f\"DEEPSEEK_API_KEY: {os.environ.get('DEEPSEEK_API_KEY', 'NOT SET')[:10]}...\")\n",
    "\n",
    "# å…ˆå•ç‹¬æµ‹è¯• DeepSeek API æ˜¯å¦æ­£å¸¸\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "    max_tokens=10\n",
    ")\n",
    "print(f\"DeepSeek API æµ‹è¯•: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "try:\n",
    "    result1 = pipeline.run(\n",
    "        \"å¸®æˆ‘åˆ†æä¸€ä¸‹å¹³å®‰é“¶è¡Œ(000001)æœ€è¿‘ä¸€å¹´çš„èµ°åŠ¿ï¼Œé¢„æµ‹æœªæ¥30å¤©çš„ä»·æ ¼è¶‹åŠ¿\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"é”™è¯¯ç±»å‹: {type(e).__name__}\")\n",
    "    print(f\"é”™è¯¯ä¿¡æ¯: {e}\")\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
